"use strict";(self.webpackChunkfluss_website=self.webpackChunkfluss_website||[]).push([[8977],{7548:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var s=r(6399),a=r(4848),t=r(8453);const o={slug:"fluss-java-client",title:"Apache Fluss Java Client: A Deep Dive",authors:["giannis"]},i=void 0,l={authorsImageUrls:[void 0]},c=[{value:"Introduction",id:"introduction",level:2},{value:"Preflight Check",id:"preflight-check",level:2},{value:"Operating The Cluster",id:"operating-the-cluster",level:2},{value:"Schema Definitions",id:"schema-definitions",level:3},{value:"Log table (sensor readings)",id:"log-table-sensor-readings",level:4},{value:"Primary Key table (sensor information)",id:"primary-key-table-sensor-information",level:4},{value:"Table Creation",id:"table-creation",level:3},{value:"Table Writes",id:"table-writes",level:2},{value:"Scans &amp; Lookups",id:"scans--lookups",level:2},{value:"Column Pruning Scans",id:"column-pruning-scans",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Banner",src:r(2976).A+"",width:"1477",height:"975"})}),"\n",(0,a.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsxs)(n.p,{children:["Apache Fluss is a streaming data storage system built for real-time analytics, serving as a low-latency data layer in modern data Lakehouses.\nIt supports sub-second streaming reads and writes, storing data in a columnar format for efficiency, and offers two flexible table types: ",(0,a.jsx)(n.strong,{children:"append-only Log Tables"})," and ",(0,a.jsx)(n.strong,{children:"updatable Primary Key Tables"}),".\nIn practice, this means Fluss can ingest high-throughput event streams ",(0,a.jsx)(n.em,{children:"(using log tables)"})," while also maintaining ",(0,a.jsx)(n.em,{children:"up-to-date"})," reference data or state ",(0,a.jsx)(n.em,{children:"(using primary key tables)"}),", a combination ideal for\nscenarios like IoT, where you might stream sensor readings and look up information for those sensors in real-time, without\nthe need for external K/V stores."]}),"\n",(0,a.jsxs)(n.p,{children:["In this tutorial, we'll introduce the ",(0,a.jsx)(n.strong,{children:"Fluss Java Client"})," by walking through a simple home IoT system example.\nWe will use ",(0,a.jsx)(n.code,{children:"Fluss's Admin client"})," to create a primary key table for sensor information and a log table for sensor readings, then use the client\nto write data to these tables and read/enrich the streaming sensor data."]}),"\n",(0,a.jsx)(n.p,{children:"By the end, you'll see how a sensor reading can be ingested into a log table and immediately enriched with information from a primary key table (essentially performing a real-time lookup join for streaming data enrichment)."}),"\n",(0,a.jsx)(n.h2,{id:"preflight-check",children:"Preflight Check"}),"\n",(0,a.jsxs)(n.p,{children:["The full source code can be found ",(0,a.jsx)(n.a,{href:"https://github.com/ververica/ververica-fluss-examples/tree/main/fluss-java-client",children:"here"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-shell",children:"docker compose up\n"})}),"\n",(0,a.jsxs)(n.p,{children:["The first thing we need to do is establish a connection to the Fluss cluster.\nThe ",(0,a.jsx)(n.code,{children:"Connection"})," is the main entry point for the Fluss client, from which we obtain an ",(0,a.jsx)(n.code,{children:"Admin"})," (for metadata operations) and Table instances (for data operations)"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:'// Configure connection to Fluss cluster\nConfiguration conf = new Configuration();\nconf.setString("bootstrap.servers", "localhost:9123");  // Fluss server endpoint\nConnection connection = ConnectionFactory.createConnection(conf);\n\n// Get Admin client for managing databases and tables\nAdmin admin = connection.getAdmin();\n'})}),"\n",(0,a.jsx)(n.p,{children:"The above code snippet shows the bare minimum requirements for connecting and interacting with a Fluss Cluster.\nFor our example we will use the following mock data - to keep things simple - which you can find below:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:"public static final List<SensorReading> readings = List.of(\n        new SensorReading(1, LocalDateTime.of(2025, 6, 23, 9, 15), 22.5, 45.0, 1013.2, 87.5),\n        new SensorReading(2, LocalDateTime.of(2025, 6, 23, 9, 30), 23.1, 44.5, 1013.1, 88.0),\n        new SensorReading(3, LocalDateTime.of(2025, 6, 23, 9, 45), 21.8, 46.2, 1012.9, 86.9),\n        new SensorReading(4, LocalDateTime.of(2025, 6, 23, 10, 0), 24.0, 43.8, 1013.5, 89.2),\n        new SensorReading(5, LocalDateTime.of(2025, 6, 23, 10, 15), 22.9, 45.3, 1013.0, 87.8),\n        new SensorReading(6, LocalDateTime.of(2025, 6, 23, 10, 30), 23.4, 44.9, 1013.3, 88.3),\n        new SensorReading(7, LocalDateTime.of(2025, 6, 23, 10, 45), 21.7, 46.5, 1012.8, 86.5),\n        new SensorReading(8, LocalDateTime.of(2025, 6, 23, 11, 0), 24.2, 43.5, 1013.6, 89.5),\n        new SensorReading(9, LocalDateTime.of(2025, 6, 23, 11, 15), 23.0, 45.1, 1013.2, 87.9),\n        new SensorReading(10, LocalDateTime.of(2025, 6, 23, 11, 30), 22.6, 45.7, 1013.0, 87.4)\n);\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:'public static final List<SensorInfo> sensorInfos = List.of(\n        new SensorInfo(1, "Outdoor Temp Sensor", "Temperature", "Roof", LocalDate.of(2024, 1, 15), "OK", LocalDateTime.of(2025, 6, 23, 9, 15)),\n        new SensorInfo(2, "Main Lobby Sensor", "Humidity", "Lobby", LocalDate.of(2024, 2, 20), "ERROR", LocalDateTime.of(2025, 6, 23, 9, 30)),\n        new SensorInfo(3, "Server Room Sensor", "Temperature", "Server Room", LocalDate.of(2024, 3, 10), "MAINTENANCE", LocalDateTime.of(2025, 6, 23, 9, 45)),\n        new SensorInfo(4, "Warehouse Sensor", "Pressure", "Warehouse", LocalDate.of(2024, 4, 5), "OK", LocalDateTime.of(2025, 6, 23, 10, 0)),\n        new SensorInfo(5, "Conference Room Sensor", "Humidity", "Conference Room", LocalDate.of(2024, 5, 25), "OK", LocalDateTime.of(2025, 6, 23, 10, 15)),\n        new SensorInfo(6, "Office 1 Sensor", "Temperature", "Office 1", LocalDate.of(2024, 6, 18), "LOW_BATTERY", LocalDateTime.of(2025, 6, 23, 10, 30)),\n        new SensorInfo(7, "Office 2 Sensor", "Humidity", "Office 2", LocalDate.of(2024, 7, 12), "OK", LocalDateTime.of(2025, 6, 23, 10, 45)),\n        new SensorInfo(8, "Lab Sensor", "Temperature", "Lab", LocalDate.of(2024, 8, 30), "ERROR", LocalDateTime.of(2025, 6, 23, 11, 0)),\n        new SensorInfo(9, "Parking Lot Sensor", "Pressure", "Parking Lot", LocalDate.of(2024, 9, 14), "OK", LocalDateTime.of(2025, 6, 23, 11, 15)),\n        new SensorInfo(10, "Backyard Sensor", "Temperature", "Backyard", LocalDate.of(2024, 10, 3), "OK", LocalDateTime.of(2025, 6, 23, 11, 30)),\n\n        // SEND SOME UPDATES\n        new SensorInfo(2, "Main Lobby Sensor", "Humidity", "Lobby", LocalDate.of(2024, 2, 20), "ERROR", LocalDateTime.of(2025, 6, 23, 9, 48)),\n        new SensorInfo(8, "Lab Sensor", "Temperature", "Lab", LocalDate.of(2024, 8, 30), "ERROR", LocalDateTime.of(2025, 6, 23, 11, 16))\n);\n'})}),"\n",(0,a.jsx)(n.h2,{id:"operating-the-cluster",children:"Operating The Cluster"}),"\n",(0,a.jsx)(n.p,{children:"Let's create a database for our IoT data, and within it define two tables:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sensor Readings Table:"})," A log table that will collect time-series readings from sensors (like temperature and humidity readings). This table is append-only (new records are added continuously, with no updates/deletes) which is ideal for immutable event streams"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sensor Information Table:"})," A primary key table that stores metadata for each sensor (like sensor ID, location, type). Each ",(0,a.jsx)(n.code,{children:"sensorId"})," will be unique and acts as the primary key. This table can be updated as sensor info changes (e.g., sensor relocated or reconfigured)."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Using the Admin client, we can programmatically create these tables."}),"\n",(0,a.jsx)(n.p,{children:"First, we'll ensure the database exists (creating it if not), then define schemas for each table and create them:"}),"\n",(0,a.jsx)(n.h3,{id:"schema-definitions",children:"Schema Definitions"}),"\n",(0,a.jsx)(n.h4,{id:"log-table-sensor-readings",children:"Log table (sensor readings)"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:'public static Schema getSensorReadingsSchema() {\n    return Schema.newBuilder()\n            .column("sensorId", DataTypes.INT())\n            .column("timestamp", DataTypes.TIMESTAMP())\n            .column("temperature", DataTypes.DOUBLE())\n            .column("humidity", DataTypes.DOUBLE())\n            .column("pressure", DataTypes.DOUBLE())\n            .column("batteryLevel", DataTypes.DOUBLE())\n            .build();\n}\n'})}),"\n",(0,a.jsx)(n.h4,{id:"primary-key-table-sensor-information",children:"Primary Key table (sensor information)"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:'public static Schema getSensorInfoSchema() {\n    return Schema.newBuilder()\n            .column("sensorId", DataTypes.INT())\n            .column("name", DataTypes.STRING())\n            .column("type", DataTypes.STRING())\n            .column("location", DataTypes.STRING())\n            .column("installationDate", DataTypes.DATE())\n            .column("state", DataTypes.STRING())\n            .column("lastUpdated", DataTypes.TIMESTAMP())\n            .primaryKey("sensorId")             <-- Define a Primary Key\n            .build();\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"table-creation",children:"Table Creation"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:'public static void setupTables(Admin admin) throws ExecutionException, InterruptedException {\n    TableDescriptor readingsDescriptor = TableDescriptor.builder()\n            .schema(getSensorReadingsSchema())\n            .distributedBy(3, "sensorId")\n            .comment("This is the sensor readings table")\n            .build();\n\n    // drop the tables or ignore if they exist\n    admin.dropTable(readingsTablePath, true).get();\n    admin.dropTable(sensorInfoTablePath, true).get();\n     \n    admin.createTable(readingsTablePath, readingsDescriptor, true).get();\n    \n    TableDescriptor sensorInfoDescriptor = TableDescriptor.builder()\n            .schema(getSensorInfoSchema())\n            .distributedBy(3, "sensorId")\n            .comment("This is the sensor information table")\n            .build();\n     \n    admin.createTable(sensorInfoTablePath, sensorInfoDescriptor, true).get();\n}\n'})}),"\n",(0,a.jsxs)(n.p,{children:["We specify a distribution with ",(0,a.jsx)(n.code,{children:'.distributedBy(3, "sensorId")'}),".\nFluss tables are partitioned into buckets (similar to partitions in Kafka topics) for scalability.\nHere we use 3 buckets, meaning data gets distributed across 3 buckets. Multiple buckets allow for higher throughput or to parallelize reads/writes.\nIf using multiple buckets, Fluss would hash on the bucket key (",(0,a.jsx)(n.code,{children:"sensorId"})," in our case) to assign records to buckets."]}),"\n",(0,a.jsxs)(n.p,{children:["For the ",(0,a.jsx)(n.code,{children:"sensor_readings"})," table, we define a schema without any primary key. In Fluss, a table created without a primary key clause is a Log Table.\nA log table only supports appending new records (no updates or deletes), making it perfect for immutable time-series data or logs."]}),"\n",(0,a.jsxs)(n.p,{children:["In the log table, specifying a bucket key like ",(0,a.jsx)(n.code,{children:"sensorId"})," ensures all readings from the same sensor end up to the same bucket providing strict ordering guarantees."]}),"\n",(0,a.jsx)(n.p,{children:"With our tables created let's go and write some data."}),"\n",(0,a.jsx)(n.h2,{id:"table-writes",children:"Table Writes"}),"\n",(0,a.jsx)(n.p,{children:"With our tables in place, let's insert some data using the Fluss Java API.\nThe client allows us to write or read data from it.\nWe'll demonstrate two patterns:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Upserting"})," into the primary key table (sensor information)."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Appending"})," to the log table (sensor readings)."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Fluss provides specialized writer interfaces for each table type: an ",(0,a.jsx)(n.strong,{children:"UpsertWriter"})," for primary key tables and an ",(0,a.jsx)(n.strong,{children:"AppendWriter"})," for log tables.\nUnder the hood, the Fluss client currently expects data as ",(0,a.jsx)(n.strong,{children:"GenericRow"})," objects (a generic row data format)."]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," Internally Fluss uses ",(0,a.jsx)(n.strong,{children:"InternalRow"})," as an optimized, binary representation of data for better performance and memory efficiency.\n",(0,a.jsx)(n.strong,{children:"GenericRow"})," is a generic implementation of InternalRow. This allows developers to interact with data easily while Fluss processes it efficiently using the underlying binary format."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Since we are creating ",(0,a.jsx)(n.strong,{children:"Pojos"})," though this means that we need to convert these into a GenericRow in order to write them into Fluss."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:"public static GenericRow energyReadingToRow(SensorReading reading) {\n    GenericRow row = new GenericRow(SensorReading.class.getDeclaredFields().length);\n    row.setField(0, reading.sensorId());\n    row.setField(1, TimestampNtz.fromLocalDateTime(reading.timestamp()));\n    row.setField(2, reading.temperature());\n    row.setField(3, reading.humidity());\n    row.setField(4, reading.pressure());\n    row.setField(5, reading.batteryLevel());\n    return row;\n}\npublic static GenericRow sensorInfoToRow(SensorInfo sensorInfo) {\n    GenericRow row = new GenericRow(SensorInfo.class.getDeclaredFields().length);\n    row.setField(0, sensorInfo.sensorId());\n    row.setField(1, BinaryString.fromString(sensorInfo.name()));\n    row.setField(2, BinaryString.fromString(sensorInfo.type()));\n    row.setField(3, BinaryString.fromString(sensorInfo.location()));\n    row.setField(4, (int) sensorInfo.installationDate().toEpochDay());\n    row.setField(5, BinaryString.fromString(sensorInfo.state()));\n    row.setField(6, TimestampNtz.fromLocalDateTime(sensorInfo.lastUpdated()));     \n    return row;\n}\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," For certain data types like ",(0,a.jsx)(n.code,{children:"String"})," or ",(0,a.jsx)(n.code,{children:"LocalDateTime"})," we need to use certain functions like\n",(0,a.jsx)(n.code,{children:'BinaryString.fromString("string_value")'})," or ",(0,a.jsx)(n.code,{children:"TimestampNtz.fromLocalDateTime(datetime)"})," otherwise you might\ncome across some conversion exceptions."]}),"\n",(0,a.jsxs)(n.p,{children:["Let's start by writing data to the ",(0,a.jsx)(n.code,{children:"Log Table"}),". This requires getting an ",(0,a.jsx)(n.code,{children:"AppendWriter"})," as follows:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:'logger.info("Creating table writer for table {} ...", AppUtils.SENSOR_READINGS_TBL);\nTable table = connection.getTable(AppUtils.getSensorReadingsTablePath());\nAppendWriter writer = table.newAppend().createWriter();\n\nAppUtils.readings.forEach(reading -> {\n    GenericRow row = energyReadingToRow(reading);\n    writer.append(row);\n});\nwriter.flush();\n\nlogger.info("Sensor Readings Written Successfully.");\n'})}),"\n",(0,a.jsx)(n.p,{children:"At this point we have successfully written 10 sensor readings to our table."}),"\n",(0,a.jsxs)(n.p,{children:["Next, let's write data to the ",(0,a.jsx)(n.code,{children:"Primary Key Table"}),". This requires getting an ",(0,a.jsx)(n.code,{children:"UpsertWriter"})," as follows:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:'logger.info("Creating table writer for table {} ...", AppUtils.SENSOR_INFORMATION_TBL);\nTable sensorInfoTable = connection.getTable(AppUtils.getSensorInfoTablePath());\nUpsertWriter upsertWriter = sensorInfoTable.newUpsert().createWriter();\n\nAppUtils.sensorInfos.forEach(sensorInfo -> {\n    GenericRow row = sensorInfoToRow(sensorInfo);\n    upsertWriter.upsert(row);\n});\n\nupsertWriter.flush();\n'})}),"\n",(0,a.jsx)(n.p,{children:"At this point we have successfully written 10 sensor information records to our table, because\nupdates will be handled on the primary key and merged."}),"\n",(0,a.jsx)(n.h2,{id:"scans--lookups",children:"Scans & Lookups"}),"\n",(0,a.jsx)(n.p,{children:"Now comes the real-time data enrichment part of our example.\nWe want to simulate a process where each incoming sensor reading is immediately looked up against the sensor information table to add context (like location and type) to the raw reading.\nThis is a common pattern in streaming systems, often achieved with lookup joins."}),"\n",(0,a.jsxs)(n.p,{children:["With the Fluss Java client, we can do this by combining a ",(0,a.jsx)(n.strong,{children:"log scanner on the readings table"})," with ",(0,a.jsx)(n.strong,{children:"point lookups on the sensor information table"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["To consume data from a Fluss table, we use a *",(0,a.jsx)(n.em,{children:"Scanner"}),".\nFor a log table, Fluss provides a ",(0,a.jsx)(n.strong,{children:"LogScanner"})," that allows us to ",(0,a.jsx)(n.strong,{children:"subscribe to one or more buckets"})," and poll for new records."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:"LogScanner logScanner = readingsTable.newScan()         \n        .createLogScanner();\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:"Lookuper sensorInforLookuper = sensorInfoTable\n        .newLookup()\n        .createLookuper();\n"})}),"\n",(0,a.jsxs)(n.p,{children:["We set up a scanner on the ",(0,a.jsx)(n.code,{children:"sensor_readings"})," table, and next we need to subscribe to all its buckets, and then poll for any available records:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:'int numBuckets = readingsTable.getTableInfo().getNumBuckets();\nfor (int i = 0; i < numBuckets; i++) {     \n    logger.info("Subscribing to Bucket {}.", i);\n    logScanner.subscribeFromBeginning(i);\n}\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Start polling for records. For each incoming record we will use the ",(0,a.jsx)(n.strong,{children:"Lookuper"})," to ",(0,a.jsx)(n.code,{children:"lookup"})," sensor information from the primary key table,\nand creating a ",(0,a.jsx)(n.strong,{children:"SensorReadingEnriched"})," record."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:' while (true) {\n    logger.info("Polling for records...");\n    ScanRecords scanRecords = logScanner.poll(Duration.ofSeconds(1));\n    for (TableBucket bucket : scanRecords.buckets()) {\n        for (ScanRecord record : scanRecords.records(bucket)) {\n            InternalRow row = record.getRow();\n            \n            logger.info("Received reading from sensor \'{}\' at \'{}\'.", row.getInt(0), row.getTimestampNtz(1, 6).toString());\n            logger.info("Performing lookup to get the information for sensor \'{}\'. ", row.getInt(0));\n            LookupResult lookupResult = sensorInforLookuper.lookup(row).get();\n            SensorInfo sensorInfo = lookupResult.getRowList().stream().map(r -> new SensorInfo(\n                    r.getInt(0),\n                    r.getString(1).toString(),\n                    r.getString(2).toString(),\n                    r.getString(3).toString(),\n                    LocalDate.ofEpochDay(r.getInt(4)),\n                    r.getString(5).toString(),\n                    LocalDateTime.parse(r.getTimestampNtz(6, 6).toString(), formatter)\n            )).findFirst().get();\n            logger.info("Retrieved information for \'{}\' with id: {}", sensorInfo.name(), sensorInfo.sensorId());\n\n            SensorReading reading = new SensorReading(\n                    row.getInt(0),\n                    LocalDateTime.parse(row.getTimestampNtz(1, 6).toString(), formatter),\n                    row.getDouble(2),\n                    row.getDouble(3),\n                    row.getDouble(4),\n                    row.getDouble(5)\n            );\n\n            SensorReadingEnriched readingEnriched = new SensorReadingEnriched(\n                    reading.sensorId(),\n                    reading.timestamp(),\n                    reading.temperature(),\n                    reading.humidity(),\n                    reading.pressure(),\n                    reading.batteryLevel(),\n                    sensorInfo.name(),\n                    sensorInfo.type(),\n                    sensorInfo.location(),\n                    sensorInfo.state()\n            );\n            logger.info("Bucket: {} - {}", bucket, readingEnriched);\n            logger.info("---------------------------------------");\n        }\n    }\n}\n'})}),"\n",(0,a.jsx)(n.p,{children:"Let's summarize what's happening here:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["We create a LogScanner for the ",(0,a.jsx)(n.code,{children:"sensor_readings"})," table using ",(0,a.jsx)(n.em,{children:"table.newScan().createLogScanner()"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["We subscribe to each bucket of the table from the beginning (offset 0). Subscribing ",(0,a.jsx)(n.code,{children:"from beginning"})," means we'll read all existing data from the start; alternatively, one could subscribe from the latest position to only get new incoming data or based on other attributes like time. In our case, since we just inserted data, from-beginning will capture those inserts."]}),"\n",(0,a.jsxs)(n.li,{children:["We then call ",(0,a.jsx)(n.code,{children:"poll(Duration)"})," on the scanner to retrieve available records, waiting up to the given timeout (1 second here). This returns a ",(0,a.jsx)(n.code,{children:"ScanRecords"})," batch containing any records that were present. We iterate over each ",(0,a.jsx)(n.code,{children:"TableBucket"})," and then over each ",(0,a.jsx)(n.code,{children:"ScanRecord"})," within that bucket."]}),"\n",(0,a.jsxs)(n.li,{children:["For each record, we extract the fields via the InternalRow interface (which provides typed access to each column in the row) and ",(0,a.jsx)(n.strong,{children:"convert them into a Pojo"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["Next, for each reading, we perform a ",(0,a.jsx)(n.strong,{children:"lookup"})," on the ",(0,a.jsx)(n.strong,{children:"sensor_information"})," table to get the sensor's info. We construct a key (GenericRow with just the sensor_id) and use ",(0,a.jsx)(n.strong,{children:"sensorTable.newLookup().createLookuper().lookup(key)"}),". This performs a point lookup by primary key and returns a ",(0,a.jsx)(n.code,{children:"LookupResult future"}),"; we call ",(0,a.jsx)(n.code,{children:".get()"})," to get the result synchronously. If present, we retrieve the InternalRow of the sensor information and ",(0,a.jsx)(n.strong,{children:"convert it into a Pojo"}),"."]}),"\n",(0,a.jsx)(n.li,{children:"We then combine the data: logging an enriched message that includes the sensor's information alongside the reading values."}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Fluss's lookup API gives us quick primary-key retrieval from a table, which is exactly what we need to enrich the streaming data.\nIn a real application, this enrichment could be done on the fly in a streaming job (and indeed ",(0,a.jsx)(n.strong,{children:"Fluss is designed to support high-QPS lookup joins in real-time pipelines"}),"), but here we're simulating it with client calls for clarity."]}),"\n",(0,a.jsxs)(n.p,{children:["If you run the above code found ",(0,a.jsx)(n.a,{href:"https://github.com/ververica/ververica-fluss-examples",children:"here"}),", you should see an output like the following:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-shell",children:"16:07:13.594 INFO  [DownloadRemoteLog-[sensors_db.sensor_readings_tbl]] c.a.f.c.t.s.l.RemoteLogDownloader$DownloadRemoteLogThread - Starting\n16:07:13.599 INFO  [main] com.ververica.scanner.FlussScanner - Subscribing to Bucket 0.\n16:07:13.599 INFO  [main] com.ververica.scanner.FlussScanner - Subscribing to Bucket 1.\n16:07:13.600 INFO  [main] com.ververica.scanner.FlussScanner - Subscribing to Bucket 2.\n16:07:13.600 INFO  [main] com.ververica.scanner.FlussScanner - Polling for records...\n16:07:13.965 INFO  [main] com.ververica.scanner.FlussScanner - Received reading from sensor '3' at '2025-06-23T09:45'.\n16:07:13.966 INFO  [main] com.ververica.scanner.FlussScanner - Performing lookup to get the information for sensor '3'. \n16:07:14.032 INFO  [main] com.ververica.scanner.FlussScanner - Retrieved information for 'Server Room Sensor' with id: 3\n16:07:14.033 INFO  [main] com.ververica.scanner.FlussScanner - Bucket: TableBucket{tableId=2, bucket=1} - SensorReadingEnriched[sensorId=3, timestamp=2025-06-23T09:45, temperature=21.8, humidity=46.2, pressure=1012.9, batteryLevel=86.9, name=Server Room Sensor, type=Temperature, location=Server Room, state=MAINTENANCE]\n16:07:14.045 INFO  [main] com.ververica.scanner.FlussScanner - ---------------------------------------\n16:07:14.046 INFO  [main] com.ververica.scanner.FlussScanner - Received reading from sensor '4' at '2025-06-23T10:00'.\n16:07:14.046 INFO  [main] com.ververica.scanner.FlussScanner - Performing lookup to get the information for sensor '4'. \n16:07:14.128 INFO  [main] com.ververica.scanner.FlussScanner - Retrieved information for 'Warehouse Sensor' with id: 4\n16:07:14.128 INFO  [main] com.ververica.scanner.FlussScanner - Bucket: TableBucket{tableId=2, bucket=1} - SensorReadingEnriched[sensorId=4, timestamp=2025-06-23T10:00, temperature=24.0, humidity=43.8, pressure=1013.5, batteryLevel=89.2, name=Warehouse Sensor, type=Pressure, location=Warehouse, state=OK]\n16:07:14.129 INFO  [main] com.ververica.scanner.FlussScanner - ---------------------------------------\n16:07:14.129 INFO  [main] com.ververica.scanner.FlussScanner - Received reading from sensor '8' at '2025-06-23T11:00'.\n16:07:14.129 INFO  [main] com.ververica.scanner.FlussScanner - Performing lookup to get the information for sensor '8'. \n16:07:14.229 INFO  [main] com.ververica.scanner.FlussScanner - Retrieved information for 'Lab Sensor' with id: 8\n16:07:14.229 INFO  [main] com.ververica.scanner.FlussScanner - Bucket: TableBucket{tableId=2, bucket=1} - SensorReadingEnriched[sensorId=8, timestamp=2025-06-23T11:00, temperature=24.2, humidity=43.5, pressure=1013.6, batteryLevel=89.5, name=Lab Sensor, type=Temperature, location=Lab, state=ERROR]\n16:07:14.229 INFO  [main] com.ververica.scanner.FlussScanner - ---------------------------------------\n"})}),"\n",(0,a.jsx)(n.h2,{id:"column-pruning-scans",children:"Column Pruning Scans"}),"\n",(0,a.jsxs)(n.p,{children:["Column pruning lets you fetch only the columns you need, ",(0,a.jsx)(n.strong,{children:"reducing network overhead and improving read performance"}),". With Fluss\u2019s Java client, you can specify a subset of columns in your scan:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:'LogScanner logScanner = readingsTable.newScan()\n    .project(List.of("sensorId", "timestamp", "temperature"))\n    .createLogScanner();\n'})}),"\n",(0,a.jsx)(n.p,{children:"Let's break this down:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:".project(...)"})," instructs the client to request only the specified columns (sensorId,timestamp and temperature) from the server."]}),"\n",(0,a.jsxs)(n.li,{children:["Fluss\u2019s columnar storage means non-requested columns (e.g., humidity, etc.) ",(0,a.jsx)(n.strong,{children:"aren\u2019t transmitted, saving bandwidth and reducing client-side parsing overhead"}),"."]}),"\n",(0,a.jsx)(n.li,{children:"You can combine projection with filters or lookups to further optimize your data access patterns."}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Example output:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-shell",children:"16:12:35.114 INFO  [main] com.ververica.scanner.FlussScanner - Subscribing to Bucket 0.\n16:12:35.114 INFO  [main] com.ververica.scanner.FlussScanner - Subscribing to Bucket 1.\n16:12:35.114 INFO  [main] com.ververica.scanner.FlussScanner - Subscribing to Bucket 2.\n16:12:35.114 INFO  [main] com.ververica.scanner.FlussScanner - Polling for records...\n16:12:35.171 INFO  [main] com.ververica.scanner.FlussScanner - Bucket: TableBucket{tableId=2, bucket=1} - (3,2025-06-23T09:45,21.8)\n16:12:35.172 INFO  [main] com.ververica.scanner.FlussScanner - ---------------------------------------\n16:12:35.172 INFO  [main] com.ververica.scanner.FlussScanner - Bucket: TableBucket{tableId=2, bucket=1} - (4,2025-06-23T10:00,24.0)\n16:12:35.172 INFO  [main] com.ververica.scanner.FlussScanner - ---------------------------------------\n16:12:35.172 INFO  [main] com.ververica.scanner.FlussScanner - Bucket: TableBucket{tableId=2, bucket=1} - (8,2025-06-23T11:00,24.2)\n16:12:35.172 INFO  [main] com.ververica.scanner.FlussScanner - ---------------------------------------\n16:12:35.172 INFO  [main] com.ververica.scanner.FlussScanner - Bucket: TableBucket{tableId=2, bucket=1} - (10,2025-06-23T11:30,22.6)\n"})}),"\n",(0,a.jsx)(n.p,{children:"Notice, how only the requested columns are returned from the server."}),"\n",(0,a.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,a.jsxs)(n.p,{children:["In this blog post, we've introduced the Fluss Java Client by guiding you through a full example of creating tables, writing data, and reading/enriching data in real-time.\nWe covered how to use the ",(0,a.jsx)(n.code,{children:"Admin"})," client to define a ",(0,a.jsx)(n.strong,{children:"Primary Key table"})," (for reference data that can be updated) and a ",(0,a.jsx)(n.strong,{children:"Log table"})," (for immutable event streams), and how to use the Fluss client to upsert and append data accordingly.\nWe also demonstrated reading from a log table using a scanner and performing a lookup on a primary key table to enrich the streaming data on the fly."]}),"\n",(0,a.jsxs)(n.p,{children:["This IoT sensor scenario is just one example of Fluss in action and also highlights the ",(0,a.jsx)(n.strong,{children:"Stream/Table duality"})," within the same system.\nFluss's ability to handle high-throughput append streams and fast key-based lookups makes it well-suited for real-time analytics use cases like this and many others.\nWith this foundation, you can explore more advanced features of Fluss to build robust real-time data applications. Happy streaming! \ud83c\udf0a"]}),"\n",(0,a.jsxs)(n.p,{children:["And before you go \ud83d\ude0a don\u2019t forget to give Fluss \ud83c\udf0a some \u2764\ufe0f via \u2b50 on ",(0,a.jsx)(n.a,{href:"https://github.com/alibaba/fluss",children:"GitHub"})]})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},2976:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/images/banner-9b4e9683efcde75c4961249525c8f269.png"},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>i});var s=r(6540);const a={},t=s.createContext(a);function o(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),s.createElement(t.Provider,{value:n},e.children)}},6399:e=>{e.exports=JSON.parse('{"permalink":"/blog/fluss-java-client","source":"@site/blog/2025-07-07-fluss-java-client.md","title":"Apache Fluss Java Client: A Deep Dive","description":"\x3c!--","date":"2025-07-07T00:00:00.000Z","tags":[],"hasTruncateMarker":true,"authors":[{"name":"Giannis Polyzos","title":"Fluss Contributor","url":"https://github.com/polyzos","imageURL":"https://github.com/polyzos.png","key":"giannis","page":null}],"frontMatter":{"slug":"fluss-java-client","title":"Apache Fluss Java Client: A Deep Dive","authors":["giannis"]},"unlisted":false,"prevItem":{"title":"Fluss Joins the Apache Incubator","permalink":"/blog/fluss-joins-asf"},"nextItem":{"title":"Tiering Service Deep Dive","permalink":"/blog/tiering-service"}}')}}]);