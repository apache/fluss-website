"use strict";(self.webpackChunkfluss_website=self.webpackChunkfluss_website||[]).push([[1477],{5862:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});var t=i(637),s=i(4848),a=i(8453);const r={title:"Announcing Fluss 0.7",authors:["jark"],date:new Date("2025-06-18T00:00:00.000Z"),tags:["releases"]},o=void 0,l={authorsImageUrls:[void 0]},c=[{value:"Stability Enhancements",id:"stability-enhancements",level:2},{value:"New Architecture of the Streaming Lakehouse",id:"new-architecture-of-the-streaming-lakehouse",level:2},{value:"Elastic Stateless Service",id:"elastic-stateless-service",level:3},{value:"Pluggable Lake Format",id:"pluggable-lake-format",level:3},{value:"Native Flink Command Submission",id:"native-flink-command-submission",level:3},{value:"Streaming Partition Pruning",id:"streaming-partition-pruning",level:2},{value:"Enterprise-Grade Security",id:"enterprise-grade-security",level:2},{value:"Flink DataStream Connector",id:"flink-datastream-connector",level:2},{value:"Fluss Java Client",id:"fluss-java-client",level:2},{value:"Future Roadmap",id:"future-roadmap",level:2},{value:"List of contributors",id:"list-of-contributors",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Banner",src:i(6181).A+"",width:"1322",height:"632"})}),"\n",(0,s.jsxs)(n.p,{children:["\ud83c\udf0a We are excited to announce the official release of ",(0,s.jsx)(n.strong,{children:"Fluss 0.7"}),"!"]}),"\n",(0,s.jsxs)(n.p,{children:["This version has undergone extensive improvements in ",(0,s.jsx)(n.strong,{children:"stability"}),", ",(0,s.jsx)(n.strong,{children:"architecture"}),", ",(0,s.jsx)(n.strong,{children:"performance optimization"}),", and ",(0,s.jsx)(n.strong,{children:"security"}),", further enhancing its readiness for ",(0,s.jsx)(n.strong,{children:"production environments"}),". Over the past three months, we have completed more than ",(0,s.jsx)(n.strong,{children:"250 commits"}),", making this release a significant milestone toward becoming a mature, production-grade streaming storage platform."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Improvements Diagram",src:i(2006).A+"",width:"1248",height:"778"})}),"\n",(0,s.jsx)(n.h2,{id:"stability-enhancements",children:"Stability Enhancements"}),"\n",(0,s.jsx)(n.p,{children:"In this release, we have dedicated significant effort to enhancing system stability. By building a comprehensive stability testing framework covering end-to-end processes and multi-scenario fault simulations, combined with large-scale stress testing using real business data, and through rigorous production-level stability validation in Alibaba, we have addressed and resolved over 50 issues. This has significantly improved the stability of Fluss' core modules and the overall robustness of the system. The major improvements include:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Online/Offline Node Optimization:"})," Refactored the ISR (In-Sync Replica) update mechanism and replica synchronization logic and enhanced idempotency guarantees. This significantly improves system stability and reduces the risk of data loss during node failures."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Server Metadata Caching:"})," Introduced a consistent metadata caching layer on the server side. Clients now fetch metadata from the local server cache instead of ZooKeeper, significantly reducing request latency and pressure on ZooKeeper."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Server Rack-Aware Support:"}),' During replica assignment, the system automatically avoids placing multiple replicas within the same "rack", thereby significantly improving fault tolerance and high availability. This feature is especially beneficial in multi-AZ deployments and large-scale data center disaster recovery scenarios. You can configure the "rack" of the TabletServer via setting ',(0,s.jsx)(n.code,{children:"tablet-server.rack"})," in ",(0,s.jsx)(n.code,{children:"server.yaml"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Accelerated Table Creation:"})," Leveraged batched metadata updates to reduce table initialization time. For example, the time for a table creation with 1024 buckets was reduced from minutes to milliseconds."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Optimized Read/Write Pipelines:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Introduce bucket-id-based shuffle for primary key tables to improve write throughput."}),"\n",(0,s.jsx)(n.li,{children:"Dynamically estimate the batch size based on incoming traffic to optimize memory usage and throughput."}),"\n",(0,s.jsx)(n.li,{children:"Optimize the Arrow memory release logic to enhance job stability."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"These enhancements make Fluss 0.7 ready for most production use cases."}),"\n",(0,s.jsx)(n.h2,{id:"new-architecture-of-the-streaming-lakehouse",children:"New Architecture of the Streaming Lakehouse"}),"\n",(0,s.jsx)(n.p,{children:"In Fluss 0.5, we first introduced the Streaming Lakehouse feature, with the powerful Union Read ability, we can significantly reduce the cost of streaming storage and improve the data freshness of Lakehouse."}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"Note: Union Reads allows querying and combining the results from both Lakehouse (historical) and Fluss (real-time) data."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"However, the initial implementation had architectural limitations affecting scalability and operability in production. In Fluss 0.7, we\u2019ve completely re-architected the Streaming Lakehouse feature to address these challenges."}),"\n",(0,s.jsx)(n.h3,{id:"elastic-stateless-service",children:"Elastic Stateless Service"}),"\n",(0,s.jsx)(n.p,{children:"Previously, the lake tiering service was implemented as a Flink job encapsulating Fluss as a Source and Paimon as a Sink, storing sync offsets state in Flink\u2019s State, this making it a stateful service.\nThis led to several operational issues:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Single Point of Failure:"})," The lifecycle of each table is bound to a specific Flink job. Once a job fails, the synchronization of all tables hosted by the job will be blocked."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Limited Scalability:"})," Could only scale vertically (increase job resources), not horizontally (start multiple jobs)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Inflexible Scheduling:"})," Unable to prioritize tables and dynamically assign to dedicated Flink clusters."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Opaque State:"})," Flink State being a black box made monitoring and troubleshooting the offset difficult."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"To address these challenges, we've re-architected the lake tiering service into a truly elastic and stateless component.\nThe sync offset is now persisted directly within Fluss metadata, with future plans for integration into Paimon v1.2 snapshot properties.\nFurthermore, Flink jobs have transitioned from maintaining persistent table subscriptions to a more efficient model where they process one table at a time,\ndynamically requesting the next table upon completion of the current one."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"New Architecture Diagram",src:i(9984).A+"",width:"1980",height:"1805"})}),"\n",(0,s.jsx)(n.p,{children:"This optimization significantly reduces the load on Fluss and boosts batch processing efficiency. As a result, cluster operators gain:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Enhanced Service Robustness:"})," Operators can launch multiple Flink jobs to distribute workload and increase overall system resilience."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Flexible Resource Management:"})," The ability to stop idle jobs at any time allows for immediate reclamation of valuable cluster resources."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Dynamic Task Orchestration:"})," Sync tasks can now be dynamically scheduled across all active Flink jobs, optimizing resource utilization."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Actionable Offset Visibility:"})," The offset state is now queryable, providing greater insight and control over data processing."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This design ensures end-to-end consistency across all operations.\nFurthermore, this stateless design also decouples us from the tight Flink dependency, paving the way for future lightweight execution models, such as running on FaaS (Function as a Service)."}),"\n",(0,s.jsx)(n.h3,{id:"pluggable-lake-format",children:"Pluggable Lake Format"}),"\n",(0,s.jsx)(n.p,{children:"The previous implementation had a tight coupling with Apache Paimon, which restricted our ability to integrate with other lake formats, such as Iceberg.\nWith version 0.7, we have abstracted and modularized all lake format interfaces.\nThis enhancement enables easy, plugin-style support for Iceberg and other emerging formats."}),"\n",(0,s.jsx)(n.h3,{id:"native-flink-command-submission",children:"Native Flink Command Submission"}),"\n",(0,s.jsxs)(n.p,{children:["Previously, users were limited to the ",(0,s.jsx)(n.code,{children:"lakehouse.sh"})," script for initiating the lake tiering service, which submitted jobs to the Flink cluster.\nWhile convenient, this approach restricted deployment flexibility, particularly when encountering diverse Flink deployment modes and internal product platforms.\nFluss 0.7 now addresses this by supporting ",(0,s.jsx)(n.strong,{children:"native job submission via standard Flink commands"})," (",(0,s.jsx)(n.code,{children:"flink run"}),").\nThis enhancement ensures broad compatibility with various deployment modes while significantly lowering learning and integration costs.\nThe following is an example of how to submit the lake tiering service using the native Flink command:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"flink run /path/to/fluss-flink-tiering-0.7.0.jar \\\n    --fluss.bootstrap.servers localhost:9123 \\\n    --datalake.format paimon \\\n    --datalake.paimon.metastore filesystem \\\n    --datalake.paimon.warehouse /path/to/warehouse\n"})}),"\n",(0,s.jsxs)(n.p,{children:["See more details in the ",(0,s.jsx)(n.a,{href:"/docs/maintenance/tiered-storage/lakehouse-storage/",children:"Streaming Lakehouse documentation"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"streaming-partition-pruning",children:"Streaming Partition Pruning"}),"\n",(0,s.jsx)(n.p,{children:"Partitioning is a foundational technique in modern data warehouses and Lakehouse architectures for optimizing query performance by\nlogically dividing datasets along meaningful dimensions (e.g., time, region, business line)."}),"\n",(0,s.jsxs)(n.p,{children:["Fluss 0.7 introduces ",(0,s.jsx)(n.strong,{children:"streaming partition pruning"}),", enabling selective reading of relevant partitions based on query conditions.\nFor example, if a query filters on ",(0,s.jsx)(n.code,{children:"nation_key = 'US'"}),", the Fluss Source will only read matching partitions,\nsignificantly reducing network I/O and compute overhead.\nApart from that, we also support the following advanced partition features to make partition pruning adaptable and easy to use:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Multi-level Partitioning:"})," Supports nested partition strategies (e.g., ",(0,s.jsx)(n.code,{children:"dt=20250617/region=US/business=sale"}),")."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Dynamic Partition Creation:"})," Automatically creates required partitions based on incoming data, no manual pre-creation is required."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Automatic Partition Discovery:"})," Fluss source adds matched new partitions to the subscription in real-time."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Using real business data from ",(0,s.jsx)(n.strong,{children:"Taobao - the largest online shopping platform in China,"})," we tested the read and write performance between non-partitioned and partitioned tables (with 20 auto-created partitions). The write results show that the multi-level partition and dynamic partition creation mechanism do not have a significant impact on the write performance.\n",(0,s.jsx)(n.img,{alt:"Write Perf",src:i(1762).A+"",width:"890",height:"554"})]}),"\n",(0,s.jsxs)(n.p,{children:["At the same time, under the same data scale, we tested the streaming read performance of non-partitioned tables and partitioned tables under three partition conditions:\n",(0,s.jsx)(n.strong,{children:"unconditional"}),", ",(0,s.jsx)(n.strong,{children:"medium matching"})," (hitting five partitions), and ",(0,s.jsx)(n.strong,{children:"exact matching"})," (hitting one partition).\nFrom the results, we can observe that when the partition condition only matches 1/20 of the partitions,\n",(0,s.jsx)(n.strong,{children:"the network traffic is reduced by about 20x"})," and the ",(0,s.jsx)(n.strong,{children:"processing time is reduced by nearly 9x"}),",\ndemonstrating the huge performance benefit of partition pruning in streaming reads."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Read Perf",src:i(8497).A+"",width:"836",height:"852"})}),"\n",(0,s.jsxs)(n.p,{children:["Streaming partition pruning is the second pushdown feature introduced after streaming column pruning in Fluss.\nLooking ahead, we plan to introduce ",(0,s.jsx)(n.strong,{children:"predicate pushdown with Arrow batch-level I/O pruning"})," to further enhance query efficiency."]}),"\n",(0,s.jsx)(n.h2,{id:"enterprise-grade-security",children:"Enterprise-Grade Security"}),"\n",(0,s.jsx)(n.p,{children:"To meet enterprise-grade security requirements, Fluss 0.7 fully supports Authentication and Authorization mechanisms."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Authentication"})," is the process of confirming the identity of the client.\nFluss introduced a plugin-based authentication with built-in ",(0,s.jsx)(n.strong,{children:"SASL/PLAIN"})," support, compatible with ",(0,s.jsx)(n.strong,{children:"JAAS"})," (Java Authentication and Authorization Service) configuration for both client and server credentials."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Authorization"})," controls which resources the identity can access and which operations it can perform after identity confirmation.\nFluss implements fine-grained permission control through the ",(0,s.jsx)(n.strong,{children:"ACL"})," (Access Control List) mechanism, supporting multi-level access control at the Cluster, Database, and Table levels."]}),"\n",(0,s.jsxs)(n.p,{children:["Additionally, we've integrated Flink SQL's ",(0,s.jsx)(n.code,{children:"CALL"})," statements to ease ACL permission management for users.\nFor instance, granting read access to the ",(0,s.jsx)(n.code,{children:"mydb"})," database for user ",(0,s.jsx)(n.code,{children:"Tim"})," can now be accomplished with the following command:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CALL admin_catalog.sys.add_acl(\n    resource => 'cluster.mydb', \n    permission => 'ALLOW',\n    principal => 'User:Tim', \n    operation => 'READ',\n    host => '*'\n);\n"})}),"\n",(0,s.jsxs)(n.p,{children:["For details, please refer to the ",(0,s.jsx)(n.a,{href:"/docs/security/overview/",children:"Security documentation"})," and quickstarts."]}),"\n",(0,s.jsx)(n.h2,{id:"flink-datastream-connector",children:"Flink DataStream Connector"}),"\n",(0,s.jsx)(n.p,{children:"Fluss 0.7 officially introduces the DataStream Connector, supporting both Source and Sink for reading and writing log and primary key tables. Users can now seamlessly integrate Fluss tables into Flink DataStream pipelines."}),"\n",(0,s.jsx)(n.p,{children:"Here\u2019s an example of reading data from a Fluss table into a Flink DataStream:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'FlussSource<Order> source = FlussSource.<Order>builder()\n    .setBootstrapServers("localhost:9092")\n    .setDatabase("mydb")\n    .setTable("orders")\n    // column pruning\n    .setProjectedFields("orderId", "amount")\n    .setStartingOffsets(OffsetsInitializer.earliest())\n    .setDeserializationSchema(new OrderDeserializationSchema())\n    .build();\n\nDataStreamSource<Order> stream = env.fromSource(\n    source,\n    WatermarkStrategy.noWatermarks(),\n    "Fluss Source"\n);\n'})}),"\n",(0,s.jsxs)(n.p,{children:["For usage examples and configuration parameters, see the ",(0,s.jsx)(n.a,{href:"https://alibaba.github.io/fluss-docs/docs/engine-flink/datastream/",children:"DataStream Connector documentation"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"fluss-java-client",children:"Fluss Java Client"}),"\n",(0,s.jsx)(n.p,{children:"In this version, we officially release the Fluss Java Client, a client library designed for developers working with structured stream tables. The client includes two core API modules:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Table API:"})," For table-based data operations, supporting streaming reads/writes, updates, deletions, and point queries."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Admin API:"})," For metadata management, including cluster management, table lifecycle, and access control."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The client supports forward and backward compatibility, ensuring smooth upgrades across Fluss versions. With the Fluss Java Client, developers can build online applications and data ingestion services based on Fluss, as well as enterprise-level components such as Fluss management platforms and operations monitoring systems. For detailed usage instructions, please refer to the official documentation: ",(0,s.jsx)(n.a,{href:"https://alibaba.github.io/fluss-docs/docs/apis/java-client/",children:"Fluss Java Client User Guide"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["Fluss uses Apache Arrow as its underlying storage format, enabling efficient cross-language extensions. A ",(0,s.jsx)(n.strong,{children:"Fluss Python Client"})," is planned for future releases, leveraging the rich ecosystem of ",(0,s.jsx)(n.strong,{children:"PyArrow"})," to integrate with popular data analysis tools such as ",(0,s.jsx)(n.strong,{children:"Pandas"})," and ",(0,s.jsx)(n.strong,{children:"DuckDB"}),".\nThis will further lower the barrier for real-time data exploration and analytics."]}),"\n",(0,s.jsx)(n.h2,{id:"future-roadmap",children:"Future Roadmap"}),"\n",(0,s.jsxs)(n.p,{children:["In the next releases, we will continue to enhance system robustness and operational capabilities and plan to introduce ",(0,s.jsx)(n.strong,{children:"Rolling Upgrades"})," and ",(0,s.jsx)(n.strong,{children:"Cluster Rebalance"}),".\nIn addition, with the new pluggable datalake format of the Streaming Lakehouse, we will further expand support for the mainstream datalake table formats, such as an ",(0,s.jsx)(n.strong,{children:"Apache Iceberg"})," integration.\nMeanwhile, we will explore the possibility of using Fluss in ",(0,s.jsx)(n.strong,{children:"multimodal AI"})," use cases, supporting ingestion of multimodal data,\nand integrating with ",(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"https://github.com/lancedb/lance",children:"Lance"})})," format in the Streaming Lakehouse architecture."]}),"\n",(0,s.jsxs)(n.p,{children:["Fluss is under active development. Be sure to stay updated on the project, give it a try and if you like it,\ndon\u2019t forget to give it some \u2764\ufe0f via \u2b50 on ",(0,s.jsx)(n.a,{href:"https://github.com/alibaba/fluss",children:"GitHub"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"list-of-contributors",children:"List of contributors"}),"\n",(0,s.jsx)(n.p,{children:"The Fluss community would like to express gratitude to all the contributors who made this release possible:"}),"\n",(0,s.jsx)(n.p,{children:"Benchao Li,  CaoZhen,  Feng Wang,  Giannis Polyzos,  HZY,  Hongshun Wang,  Jark Wu,  Junbo wang,  Kerwin,  Leonard Xu,  MehulBatra,  Michael Koepf,  Min Zhao,  Nicholas Jiang,  Radek Grebski,  Rohan Dubey,  Xiaojian Sun,  Yang Guo,  dao-jun,  gkatzioura,  luoyuxia,  majialong,  xiaozhou,  yunhong,  yuxia Luo,  yx9o,  zhangmang,  \u9053\u541b"})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},6181:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/banner-8cc4ea9295caf8358e14adf7a69beb01.png"},9984:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/new_tiering_service-4509c1a4b51c6821c0fe622cdda534e4.png"},2006:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/overview-255047ec7648f12c63660b40d1147c86.png"},8497:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/read_perf-66abe9aa4ee1bf9ef52dc10c59072c0f.jpg"},1762:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/write_perf-25c062766e117f2c092a79653cf69a85.jpg"},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>o});var t=i(6540);const s={},a=t.createContext(s);function r(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(a.Provider,{value:n},e.children)}},637:e=>{e.exports=JSON.parse('{"permalink":"/blog/releases/0.7","source":"@site/blog/releases/0.7.md","title":"Announcing Fluss 0.7","description":"\x3c!--","date":"2025-06-18T00:00:00.000Z","tags":[{"inline":false,"label":"releases","permalink":"/blog/tags/releases","description":"Content related release announcement."}],"hasTruncateMarker":true,"authors":[{"name":"Jark Wu","title":"Creator of Fluss project","url":"https://github.com/wuchong","imageURL":"https://github.com/wuchong.png","key":"jark","page":null}],"frontMatter":{"title":"Announcing Fluss 0.7","authors":["jark"],"date":"2025-06-18T00:00:00.000Z","tags":["releases"]},"unlisted":false,"prevItem":{"title":"Tiering Service Deep Dive","permalink":"/blog/tiering-service"},"nextItem":{"title":"Understanding Partial Updates","permalink":"/blog/partial-updates"}}')}}]);