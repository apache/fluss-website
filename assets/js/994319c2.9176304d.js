"use strict";(self.webpackChunkfluss_website=self.webpackChunkfluss_website||[]).push([[5175],{7109:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var s=i(9485),t=i(4848),r=i(8453);const o={title:"Announcing Fluss 0.6",authors:["jark"],date:new Date("2025-03-10T00:00:00.000Z"),tags:["releases"]},a=void 0,l={authorsImageUrls:[void 0]},c=[{value:"Column Compression",id:"column-compression",level:2},{value:"Merge Engine",id:"merge-engine",level:2},{value:"FirstRow Merge Engine",id:"firstrow-merge-engine",level:3},{value:"Versioned Merge Engine",id:"versioned-merge-engine",level:3},{value:"Prefix Lookup for Delta Join",id:"prefix-lookup-for-delta-join",level:2},{value:"Stability &amp; Performance Improvements",id:"stability--performance-improvements",level:2},{value:"Lakehouse Storage",id:"lakehouse-storage",level:2},{value:"Flink Integration",id:"flink-integration",level:2},{value:"Upgrade Notes",id:"upgrade-notes",level:2},{value:"Future Plan",id:"future-plan",level:2},{value:"List of Contributors",id:"list-of-contributors",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.p,{children:["The Fluss community is pleased to announce the official release of ",(0,t.jsx)(n.strong,{children:"Fluss 0.6.0"}),". This version has undergone over\nthree months of intensive development, bringing together the expertise and efforts of 45 contributors worldwide,\nwith more than 200 code commits completed. Our heartfelt thanks go out to every contributor for their invaluable support!"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Release Announcement",src:i(8309).A+"",width:"1224",height:"440"})}),"\n",(0,t.jsx)(n.p,{children:"This release introduces several exciting features:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Column Compression"}),": Reduces storage space by up to ",(0,t.jsx)(n.strong,{children:"6x"})," while preserving column pruning performance!"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Merge Engine"}),": Introduces flexible merge strategies for primary key data, addressing diverse real-time processing needs."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Prefix Lookup"}),": Delta Join functionality is now ready on the Fluss side!"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"These new features not only significantly enhance the functionality of Fluss but also represent a solid step\nforward in our journey toward building the next-generation analytical stream storage solution."}),"\n",(0,t.jsx)(n.h2,{id:"column-compression",children:"Column Compression"}),"\n",(0,t.jsxs)(n.p,{children:["Fluss uses the ",(0,t.jsx)(n.a,{href:"https://arrow.apache.org/",children:"Apache Arrow"})," columnar format for it's underlying log file storage, fully leveraging Arrow's streaming\ncolumnar capabilities to achieve highly efficient streaming reads and column pruning. Column pruning in Fluss is performed on the server side,\nwith end-to-end zero-copy optimization that allows the required column data to be sent directly to the network without\nloading it into memory from disk. This design not only significantly improves performance but also drastically reduces\nnetwork I/O costs and resource overhead. In previous ",(0,t.jsx)(n.a,{href:"/blog/fluss-intro#columnar-stream",children:"benchmark tests"}),",\nwhen 90% of the columns were pruned, Fluss achieved a 10x increase in read throughput, demonstrating its exceptional\nperformance in streaming data processing and transmission."]}),"\n",(0,t.jsxs)(n.p,{children:["While column pruning effectively reduces network I/O costs, disk storage costs remain high. To address this,\nwe have introduced ",(0,t.jsx)(n.strong,{children:"column compression"})," in this version, supporting two highly efficient compression algorithms: ",(0,t.jsx)(n.strong,{children:"ZSTD"})," and ",(0,t.jsx)(n.strong,{children:"LZ4"}),".\nThese algorithms significantly reduce data storage requirements, thereby lowering storage costs substantially.\nSince both compression and decompression are performed on the client side, the amount of data transmitted over the network is reduced,\nfurther decreasing network I/O costs. Notably, compression is applied independently to each column, ensuring that the original column pruning performance is preserved and that streaming read efficiency remains unaffected."]}),"\n",(0,t.jsx)(n.p,{children:"To validate the actual effectiveness of this feature, we conducted benchmark tests using a typical business scenario from Alibaba Taobao.\nIn the tests, we used datasets of the same scale and Flink jobs with identical resources, writing to Fluss with and without ZSTD compression,\nand compared the write throughput. Subsequently, we read data from the table and tested the read throughput.\nThe results showed that column compression not only reduced storage space by approximately 6x but also improved read and write throughput."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Compression Benchmark",src:i(8695).A+"",width:"962",height:"572"})}),"\n",(0,t.jsx)(n.p,{children:"However, enabling compression had no noticeable impact on Flink's read/write CPU and memory usage."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Compression Benchmark",src:i(6376).A+"",width:"1180",height:"542"})}),"\n",(0,t.jsx)(n.p,{children:"The performance of column pruning on compressed data was also tested. The results show that as the number of pruned columns increases,\na multiple-fold performance improvement is still achieved, maintaining the original column pruning efficiency."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Compression Benchmark",src:i(3989).A+"",width:"1196",height:"624"})}),"\n",(0,t.jsxs)(n.p,{children:["Given the significant cost savings and performance improvements achieved by column compression in general use cases,\nZSTD compression is enabled by default for log tables in Fluss 0.6. Users can disable compression by\nsetting the parameter ",(0,t.jsx)(n.code,{children:"'table.log.arrow.compression.type'='NONE'"})," on the table."]}),"\n",(0,t.jsx)(n.h2,{id:"merge-engine",children:"Merge Engine"}),"\n",(0,t.jsxs)(n.p,{children:["In this version, Fluss introduces a new Merge Engine feature for primary key tables to flexibly support merging strategies for data with the same primary key.\nThe default Merge Engine strategy for primary key tables is to retain the latest record for each primary key.\nUsers can also choose alternative Merge Engines, including the currently supported ",(0,t.jsx)(n.strong,{children:"FirstRow Merge Engine"})," and ",(0,t.jsx)(n.strong,{children:"Versioned Merge Engine"}),".\nSupport for the ",(0,t.jsx)(n.strong,{children:"Aggregate Merge Engine"})," is planned for future releases."]}),"\n",(0,t.jsx)(n.h3,{id:"firstrow-merge-engine",children:"FirstRow Merge Engine"}),"\n",(0,t.jsxs)(n.p,{children:["By setting the table property ",(0,t.jsx)(n.code,{children:"'table.merge-engine' = 'first_row'"}),", users can retain the first record for each primary key.\nWhen this configuration is enabled, the primary key table will generate an append-only changelog. This allows downstream\nFlink jobs subscribing to the table to receive an append-only stream, enabling the use of operators that do not support retraction messages,\nsuch as Window Aggregations and Interval Joins. This feature is commonly used as a replacement for log deduplication in streaming processing,\neffectively reducing costs and system complexity."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"-- create first_row primary key table\nCREATE TABLE T (\n    k  INT,\n    v1 DOUBLE,\n    v2 STRING,\n    PRIMARY KEY (k) NOT ENFORCED\n) WITH (\n    'table.merge-engine' = 'first_row'\n);\n\nINSERT INTO T VALUES (1, 2.0, 't1');\nINSERT INTO T VALUES (1, 3.0, 't2');\n\nSELECT * FROM T WHERE k = 1;\n\n-- Output\n-- +---+-----+------+\n-- | k | v1  | v2   |\n-- +---+-----+------+\n-- | 1 | 2.0 | t1   |\n-- +---+-----+------+\n"})}),"\n",(0,t.jsx)(n.h3,{id:"versioned-merge-engine",children:"Versioned Merge Engine"}),"\n",(0,t.jsxs)(n.p,{children:["The Versioned Merge Engine supports data updates based on version numbers (or event timestamps). It ensures that only the record\nwith the highest version number (or event timestamp) for each primary key is retained. This mechanism is particularly useful for\ndeduplicating or merging out-of-order data while guaranteeing eventual consistency with the upstream data source.\nIn Flink streaming processing, this feature can be used as a replacement for ",(0,t.jsx)(n.code,{children:"Rank"})," or ",(0,t.jsx)(n.code,{children:"Deduplication"})," operations, simplifying workflows and reducing costs effectively."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"-- create a versioned primary key table, `ts` as the version column\nCREATE TABLE VERSIONED (\n    a INT NOT NULL PRIMARY KEY NOT ENFORCED,\n    b STRING,\n    ts BIGINT\n ) WITH (\n    'table.merge-engine' = 'versioned',\n    'table.merge-engine.versioned.ver-column' = 'ts'\n);\nINSERT INTO VERSIONED (a, b, ts) VALUES (1, 'v1', 1000);\n\n-- insert a record with ts < 1000, ignored\nINSERT INTO VERSIONED (a, b, ts) VALUES (1, 'v2', 999);\nSELECT * FROM VERSIONED WHERE a = 1;\n-- Output\n-- +---+-----+------+\n-- | a | b   | ts   |\n-- +---+-----+------+\n-- | 1 | v1  | 1000 |\n-- +---+-----+------+\n\n\n-- insert a record with ts > 1000, updated\nINSERT INTO VERSIONED (a, b, ts) VALUES (1, 'v3', 2000);\nSELECT * FROM VERSIONED WHERE a = 1;\n-- Output\n-- +---+-----+------+\n-- | a | b   | ts   |\n-- +---+-----+------+\n-- | 1 | v3  | 2000 |\n-- +---+-----+------+\n"})}),"\n",(0,t.jsx)(n.h2,{id:"prefix-lookup-for-delta-join",children:"Prefix Lookup for Delta Join"}),"\n",(0,t.jsx)(n.p,{children:'In the scenario of building wide tables with Flink, optimizing Stream-Stream Join using Delta Join is one of the primary use cases for Fluss.\nWe have also contributed this functionality to version 0.6. Delta Join can be simply understood as a "bilateral driven lookup join", that is:\nwhen data arrives from the left stream, the right table is queried using the join key; when data arrives from the right stream, the left table is queried using the join key.\nThis approach eliminates join state like Lookup Join, while preserving the semantics of a Stream-Stream Join (any updates on either side triggers an update to the join result).\nDelta Join addresses challenges such as high cost, unstable job, checkpoint timeout, slow restart recovery, etc., in the traditional Stream-Stream Join.'}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Delta Join",src:i(5887).A+"",width:"2024",height:"884"})}),"\n",(0,t.jsx)(n.p,{children:"Overall, Delta Join relies on three core functionalities:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"CDC Stream Read for Source Table"}),": The foundational capability of Fluss."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Lookup on Join Keys for Source Table"}),": Introduced in Fluss 0.6 with Prefix Lookup support."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Delta Join Operator in Flink SQL"}),": Proposed in ",(0,t.jsx)(n.a,{href:"https://cwiki.apache.org/confluence/display/FLINK/FLIP-486%3A+Introduce+A+New+DeltaJoin",children:"FLIP-486"}),", planned for Flink 2.1."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Once FLIP-486 is completed, users will be able to achieve Delta Join using the following SQL in conjunction with Fluss's Prefix Lookup functionality:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE fluss_left_table (\n  a1 BIGINT,\n  b1 BIGINT,\n  c1 INT,\n  d1 INT,\n  PRIMARY KEY (c1,d1,a1) NOT ENFORCED  -- bucket key as a prefix of primary key\n) WITH (\n  'bucket.key' = 'c1,d1' -- define bucket key\n);\n\nCREATE TABLE fluss_right_table (\n  a2 BIGINT,\n  b2 BIGINT,\n  c2 INT,\n  d2 INT,\n  PRIMARY KEY (c2,d2,a2) NOT ENFORCED  -- bucket key as a prefix of primary key\n) WITH (\n  'bucket.key' = 'c2,d2' -- define bucket key\n);\n\n-- it will be optimized to delta join, where the join key is the bucket key of the two tables\nSELECT * FROM fluss_left_table INNER JOIN fluss_right_table\n  ON c1 = c2 AND d1 = d2\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Flink performs lookups on Fluss tables using the Join Key, which serves as the Bucket Key for the Fluss table.\nThis allows it to leverage the prefix index of the primary key in the Fluss table, enabling highly efficient lookup queries.\nThis feature in Fluss is referred to as Prefix Lookup. Currently, Prefix Lookup can also be used to perform one-to-many lookup queries.\nFor more details, please refer to the ",(0,t.jsx)(n.a,{href:"/docs/engine-flink/lookups/#prefix-lookup",children:"Prefix Lookup"})," documentation."]}),"\n",(0,t.jsx)(n.h2,{id:"stability--performance-improvements",children:"Stability & Performance Improvements"}),"\n",(0,t.jsx)(n.p,{children:"In this version, we have focused on enhancing the stability and performance of the system, resolving over 50 issues and improvements,\nand conducting in-depth optimizations on core modules. For example:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Server-side Optimization : By introducing a delayed response mechanism, CPU consumption in low-traffic scenarios has been significantly reduced, thereby improving resource utilization efficiency."}),"\n",(0,t.jsx)(n.li,{children:"Client-side Optimization : A unified memory management mechanism has been implemented to effectively prevent Out-of-Memory (OOM) issues in high-traffic scenarios while reducing the impact of garbage collection (GC) on system performance."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"These improvements have significantly enhanced Fluss's reliability and performance in high-concurrency, large-data-volume scenarios, enabling it to handle analytical stream storage workload more efficiently."}),"\n",(0,t.jsx)(n.h2,{id:"lakehouse-storage",children:"Lakehouse Storage"}),"\n",(0,t.jsx)(n.p,{children:"In previous versions, if a table in Fluss needed to enable the Lakehouse storage capability, it had to be enabled when table is created.\nOtherwise, enabling this feature later would require deleting and recreating the table. This limitation arose because enabling Lakehouse storage changes the key encoding format and bucket sharding strategy, making existing tables incompatible with the new configuration."}),"\n",(0,t.jsx)(n.p,{children:"In this version, we resolve this by detecting the cluster's default data lake format and adopting its key encoding and bucketing strategy,\nallowing Lakehouse storage to be enabled dynamically after table creation. This eliminates the need for table recreation, improving usability.\nAdditionally, Paimon dependency is upgraded to version 1.0.1 in this release."}),"\n",(0,t.jsx)(n.h2,{id:"flink-integration",children:"Flink Integration"}),"\n",(0,t.jsx)(n.p,{children:"This version introduces the following enhancements to the Flink connector:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sink Support for Ignoring Retractions:"}),"\nBoth Primary Key Tables and Log Tables now support the ",(0,t.jsx)(n.code,{children:"'sink.ignore-delete'"})," parameter in their Sink implementations. This enables better compatibility with scenarios involving retraction messages, meeting the demands of more complex streaming data processing."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Enhanced Partition Table Operations:"}),"\nPartitioned tables now support ",(0,t.jsx)(n.code,{children:"ALTER TABLE ADD/DROP PARTITION"})," and ",(0,t.jsx)(n.code,{children:"SHOW PARTITIONS"})," operations, further improving the flexibility and usability of partition management."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sink Interface Upgrade:"}),"\nThe ",(0,t.jsx)(n.code,{children:"SinkFunction"})," has been upgraded to the ",(0,t.jsx)(n.code,{children:"SinkV2"})," interface, laying the groundwork for full compatibility with Flink 2.0 in the next version. This ensures the system's scalability and compatibility in future releases."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"upgrade-notes",children:"Upgrade Notes"}),"\n",(0,t.jsx)(n.p,{children:"The Fluss community try to ensure compatibility during upgrades. However, upgrading from Fluss 0.5 to 0.6 is an incompatible upgrade.\nStarting with version 0.6, we will officially provide backward compatibility to ensure smoother and more reliable upgrades in future releases.\nTherefore, version 0.6 is the recommended version for adoption and ecosystem integration."}),"\n",(0,t.jsx)(n.h2,{id:"future-plan",children:"Future Plan"}),"\n",(0,t.jsx)(n.p,{children:"In the next version, we will focus on the development of the following core features:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"New Lake-Stream Integrated Architecture:"}),"\nA completely new architecture designed for large-scale production environments, featuring plug-in support for mainstream lake formats such as Iceberg and Hudi. This addresses key pain points in Tiering Service performance, scalability, and operational efficiency, providing a more reliable Lakehouse integrated solution for enterprise use cases."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Authentication and Authorization:"}),"\nIntroducing plugin-based authentication and fine-grained access control to meet the stringent data security requirements of enterprises."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Kafka Compatibility:"}),"\nCompatibility with the Kafka network protocol, enabling seamless integration with the Kafka ecosystem."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["For more details about the next release roadmap, please visit the community ",(0,t.jsx)(n.a,{href:"https://github.com/alibaba/fluss/discussions/556",children:"discussion page"}),". Your suggestions and contributions are highly welcomed!"]}),"\n",(0,t.jsxs)(n.p,{children:["Fluss is under active development. Be sure to stay updated on the project, give it a try and if you like it, don\u2019t forget to give it some \u2764\ufe0f via \u2b50 on ",(0,t.jsx)(n.a,{href:"https://github.com/alibaba/fluss",children:"GitHub"})]}),"\n",(0,t.jsx)(n.h2,{id:"list-of-contributors",children:"List of Contributors"}),"\n",(0,t.jsx)(n.p,{children:"The Fluss community would like to express gratitude to all the 45 contributors who made this release possible:"}),"\n",(0,t.jsx)(n.p,{children:"Benchao Li, ForwardXu, Gang Yang, Georgios Andrianakis, Giannis Polyzos, Hongshun Wang, Jark Wu, Kerwin, Leonard Xu, LiJingwei, Liu Xiao, MehulBatra, Michael Koepf, Nicholas Jiang, Ron, RunningDB, Sagar Sumit, SeungMin, Shuo Cheng, Stan, SteNicholas, Tyrantlucifer, Vipamp, WangS-C, WenjunMin, Wenston Xin, Xiaojian Sun, Yang Guo, Yubin Li, Yuepeng Pan, Zmm, benjobs, gongzhongqiang, gyang94, jon-qj, luoyuxia, moses, psxjoy, wangwj, wudi, xiaozhou, yunhong, yuxia Luo, \u7801\u754c\u63a2\u7d22, \u9053\u541b"})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8309:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/announce-9ab924e071ec69fe7af8765954f9e966.png"},8695:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/compression1-0b666a1467321b28376db725380eda3c.jpg"},6376:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/compression2-c0feecf4a8fbff819c1ad37ce03ca6e9.jpg"},3989:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/compression3-1f5de9eec6dd66394a793f26395a8f49.jpg"},5887:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/delta-join-ad3cf73fc7f3f01e306ad02fd765d26d.jpg"},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var s=i(6540);const t={},r=s.createContext(t);function o(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(r.Provider,{value:n},e.children)}},9485:e=>{e.exports=JSON.parse('{"permalink":"/blog/releases/0.6","source":"@site/blog/releases/0.6.md","title":"Announcing Fluss 0.6","description":"\x3c!--","date":"2025-03-10T00:00:00.000Z","tags":[{"inline":false,"label":"releases","permalink":"/blog/tags/releases","description":"Content related release announcement."}],"hasTruncateMarker":true,"authors":[{"name":"Jark Wu","title":"PMC member of Apache Fluss","url":"https://github.com/wuchong","imageURL":"/img/avatars/jark.png","key":"jark","page":null}],"frontMatter":{"title":"Announcing Fluss 0.6","authors":["jark"],"date":"2025-03-10T00:00:00.000Z","tags":["releases"]},"unlisted":false,"prevItem":{"title":"The Story of Fluss Logo","permalink":"/blog/unveil-fluss-logo"},"nextItem":{"title":"Towards A Unified Streaming & Lakehouse Architecture","permalink":"/blog/unified-streaming-lakehouse"}}')}}]);