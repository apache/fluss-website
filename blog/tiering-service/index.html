<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Tiering Service Deep Dive | Apache Fluss™ (incubating)</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://fluss.apache.org/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://fluss.apache.org/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://fluss.apache.org/blog/tiering-service/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Tiering Service Deep Dive | Apache Fluss™ (incubating)"><meta data-rh="true" name="description" content="&lt;!--"><meta data-rh="true" property="og:description" content="&lt;!--"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-07-01T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/gyang94"><link data-rh="true" rel="icon" href="/img/logo/fluss_favicon.svg"><link data-rh="true" rel="canonical" href="https://fluss.apache.org/blog/tiering-service/"><link data-rh="true" rel="alternate" href="https://fluss.apache.org/blog/tiering-service/" hreflang="en"><link data-rh="true" rel="alternate" href="https://fluss.apache.org/blog/tiering-service/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://D8RXQUTC99-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://fluss.apache.org/blog/tiering-service","mainEntityOfPage":"https://fluss.apache.org/blog/tiering-service","url":"https://fluss.apache.org/blog/tiering-service","headline":"Tiering Service Deep Dive","name":"Tiering Service Deep Dive","description":"<!--","datePublished":"2025-07-01T00:00:00.000Z","author":{"@type":"Person","name":"GUO Yang","description":"Fluss Contributor","url":"https://github.com/gyang94","image":"https://github.com/gyang94.png"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://fluss.apache.org/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache Fluss™ (incubating) RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache Fluss™ (incubating) Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="Apache Fluss™ (incubating)" href="/opensearch.xml">


<link rel="icon" href="/img/logo.svg">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="#0071e3"><link rel="stylesheet" href="/assets/css/styles.4e06651e.css">
<script src="/assets/js/runtime~main.fd7251cb.js" defer="defer"></script>
<script src="/assets/js/main.4f2ebb93.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo/svg/colored_logo.svg" alt="Fluss" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo/svg/colored_logo.svg" alt="Fluss" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href="/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog/">Blog</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Learn</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/learn/talks/">Talks</a></li><li><a class="dropdown__link" href="/learn/videos/">Videos</a></li></ul></div><a class="navbar__item navbar__link" href="/community/welcome/">Community</a><a class="navbar__item navbar__link" href="/roadmap/">Roadmap</a><a class="navbar__item navbar__link" href="/downloads/">Downloads</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/apache/fluss" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All our posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/fluss-joins-asf/">Fluss Joins the Apache Incubator</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/fluss-java-client/">Apache Fluss Java Client: A Deep Dive</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/tiering-service/">Tiering Service Deep Dive</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/releases/0.7/">Announcing Fluss 0.7</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/partial-updates/">Understanding Partial Updates</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/unveil-fluss-logo/">The Story of Fluss Logo</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/releases/0.6/">Announcing Fluss 0.6</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/unified-streaming-lakehouse/">Toward Streaming Lakehouse</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2024</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/fluss-intro/">Introducing Fluss</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/why-fluss/">Why Fluss? Top 4 Challenges of Kafka</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/fluss-open-source/">Fluss is Now Open Source</a></li></ul></div></nav></aside><main class="col col--7"><article class=""><header><h1 class="title_f1Hy">Tiering Service Deep Dive</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-07-01T00:00:00.000Z">July 1, 2025</time></div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/gyang94" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/gyang94.png" alt="GUO Yang"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/gyang94" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">GUO Yang</span></a></div><small class="authorTitle_nd0D" title="Fluss Contributor">Fluss Contributor</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><h2 class="anchor anchorWithStickyNavbar_LWe7" id="background">Background<a href="#background" class="hash-link" aria-label="Direct link to Background" title="Direct link to Background">​</a></h2>
<p><img decoding="async" loading="lazy" src="/assets/images/background-8a1ebc79c438a3deabba060edf8eaa0b.png" width="2036" height="924" class="img_ev3q"></p>
<p>At the core of Fluss’s Lakehouse architecture sits the <strong>Tiering Service:</strong> a smart,
policy-driven data pipeline that seamlessly bridges your real-time Fluss cluster and your cost-efficient lakehouse storage. It continuously ingests fresh events from the fluss cluster, automatically migrating older or less-frequently accessed data into colder storage tiers without interrupting ongoing queries. By balancing hot, warm, and cold storage according to configurable rules, the Tiering Service ensures that recent data remains instantly queryable while historical records are archived economically.</p>
<p>In this blog post we will take a deep dive and explore how Fluss’s Tiering Service <code>orchestrates data movement</code>, <code>preserves consistency</code>, and empowers <code>scalable</code>, <code>high-performance</code> analytics at <code>optimized costs</code>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="flink-tiering-service">Flink Tiering Service<a href="#flink-tiering-service" class="hash-link" aria-label="Direct link to Flink Tiering Service" title="Direct link to Flink Tiering Service">​</a></h2>
<p>Fluss tiering service is an Apache Flink job, which keeps moving data from fluss cluster to data lake.
The execution plan is quite straight forward. It has a three operators: a <code>source</code>, a <code>committer</code> and an empty <code>sink writer</code>.</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Source: TieringSource -&gt; TieringCommitter -&gt; Sink: Writer</span><br></span></code></pre></div></div>
<ul>
<li><strong>TieringSource</strong>: Reads records from the Fluss tiering table and writes them to the data lake.</li>
<li><strong>TieringCommitter</strong>: Commits each sync batch by advancing offsets in both the lakehouse and the Fluss cluster.</li>
<li><strong>No-Op Sink</strong>: A dummy sink that performs no action.</li>
</ul>
<p>In the sections that follow, we’ll dive into the <strong>TieringSource</strong> and <strong>TieringCommitter</strong> to see exactly how they orchestrate seamless data movement between real-time and historical storage.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tieringsource">TieringSource<a href="#tieringsource" class="hash-link" aria-label="Direct link to TieringSource" title="Direct link to TieringSource">​</a></h2>
<p><img decoding="async" loading="lazy" src="/assets/images/tiering-source-05383f4fdc58bd69e4a15c38bddf40b7.png" width="2078" height="1084" class="img_ev3q"></p>
<p>The <strong>TieringSource</strong> operator reads records from the Fluss tiering table and writes them into your data lake.
Built on Flink’s Source V2 API (<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-27%3A+Refactor+Source+Interface" target="_blank" rel="noopener noreferrer">FLIP-27</a>), it breaks down into two core components: the <strong>TieringSourceEnumerator</strong> and the <strong>TieringSourceReader</strong>.
The high-level workflow is as follows:</p>
<ol>
<li>The <strong>Enumerator</strong> queries the <strong>CoordinatorService</strong> for current tiering table metadata.</li>
<li>Once it receives the table information, the Enumerator generates <code>“splits”</code> (data partitions) and assigns them to the <strong>Reader</strong>.</li>
<li>The <strong>Reader</strong> fetches the actual data for each split.</li>
<li>Finally the <strong>Reader</strong> writes those records into the data lake.</li>
</ol>
<p>In the following sections, we’ll explore how the <strong>TieringSourceEnumerator</strong> and <strong>TieringSourceReader</strong> work under the hood to deliver reliable, scalable ingestion from Fluss into your lakehouse.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tieringsourceenumerator">TieringSourceEnumerator<a href="#tieringsourceenumerator" class="hash-link" aria-label="Direct link to TieringSourceEnumerator" title="Direct link to TieringSourceEnumerator">​</a></h3>
<p><img decoding="async" loading="lazy" src="/assets/images/tiering-source-enumerator-93519c48b1c8218d321336fa8e174617.png" width="2030" height="1252" class="img_ev3q"></p>
<p>The <strong>TieringSourceEnumerator</strong> orchestrates split creation and assignment in five key steps:</p>
<ol>
<li><strong>Heartbeat Request</strong>: Uses an RPC client to send a <code>lakeTieringHeartbeatRequest</code> to the Fluss server.</li>
<li><strong>Heartbeat Response</strong>: Receives a <code>lakeTieringHeartbeatResponse</code> that contains the tiering table metadata and sync statuses for <code>completed</code>, <code>failed</code>, and <code>in-progress</code> tables.</li>
<li><strong>Lake Tiering Info</strong>: Forwards the returned <code>lakeTieringInfo</code> to the <code>TieringSplitGenerator</code>.</li>
<li><strong>Split Generation</strong>: The <code>TieringSplitGenerator</code> produces a set of <code>TieringSplits</code>, each representing a data partition to process.</li>
<li><strong>Split Assignment</strong>: Assigns those <code>TieringSplits</code> to <code>TieringSourceReader</code> instances for downstream ingestion into the data lake.</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="rpcclient">RpcClient<a href="#rpcclient" class="hash-link" aria-label="Direct link to RpcClient" title="Direct link to RpcClient">​</a></h4>
<p>The <code>RpcClient</code> inside the <code>TieringSourceEnumerator</code> handles all RPC communication with the Fluss CoordinatorService. Its responsibilities include:</p>
<ul>
<li><strong>Sending Heartbeats</strong>: It constructs and sends a <code>LakeTieringHeartbeatRequest</code>, which carries three lists of tables—<code>tiering_tables</code> (in-progress), <code>finished_tables</code>, and <code>failed_tables</code>—along with an optional <code>request_table</code> flag to request new tiering work.</li>
<li><strong>Receiving Responses</strong>: It awaits a <code>LakeTieringHeartbeatResponse</code> that contains:<!-- -->
<ul>
<li><code>coordinator_epoch</code>: the current epoch of the coordinator.</li>
<li><code>tiering_table</code> (optional): a <code>PbLakeTieringTableInfo</code> message (with <code>table_id</code>, <code>table_path</code>, and <code>tiering_epoch</code>) describing the next table to tier.</li>
<li><code>tiering_table_resp</code>, <code>finished_table_resp</code>, and <code>failed_table_resp</code>: lists of heartbeat responses reflecting the status of each table.</li>
</ul>
</li>
<li><strong>Forwarding Metadata</strong>: It parses the returned <code>PbLakeTieringTableInfo</code> and the sync-status responses, then forwards the assembled <code>lakeTieringInfo</code> to the <code>TieringSplitGenerator</code> for split creation.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="tieringsplitgenerator">TieringSplitGenerator<a href="#tieringsplitgenerator" class="hash-link" aria-label="Direct link to TieringSplitGenerator" title="Direct link to TieringSplitGenerator">​</a></h4>
<p><img decoding="async" loading="lazy" src="/assets/images/tiering-split-generator-55e3a17880edf61dcecf9ee9eb1b36be.png" width="2012" height="1566" class="img_ev3q"></p>
<p>The <strong>TieringSplitGenerator</strong> is an important component that orchestrates efficient data synchronization between your real-time Fluss cluster and your lakehouse.
It precisely calculates the data <code>&quot;delta&quot;</code>, i.e what&#x27;s new or changed in Fluss but not yet committed to the lake and then generates <strong>TieringSplit</strong> tasks for each segment requiring synchronization.</p>
<p>To achieve this, the <code>TieringSplitGenerator</code> leverages the <code>FlussAdminClient</code> to fetch three essential pieces of metadata:</p>
<p><strong>Lake Snapshot</strong></p>
<p>The generator first invokes the lake metadata API to retrieve a <strong>LakeSnapshot</strong> object. This snapshot provides a complete picture of the current state of your data in the lakehouse, including:</p>
<ul>
<li><code>snapshotId:</code> The identifier for the latest committed snapshot in your data lake.</li>
<li><code>tableBucketsOffset:</code> A map that details the log offset in the lakehouse for each <code>TableBucket</code>.</li>
</ul>
<p><strong>Current Bucket Offsets</strong></p>
<p>Next, the <code>TieringSplitGenerator</code> queries the Fluss server to determine the <strong>current log end offset</strong> for each bucket. This effectively captures the high-water mark of incoming data streams in real time within your Fluss cluster.</p>
<p><strong>KV Snapshots (for primary-keyed tables)</strong></p>
<p>For tables that utilize primary keys, the generator also retrieves a <strong>KvSnapshots</strong> record. This record contains vital information for maintaining consistency with key-value stores:</p>
<ul>
<li><code>tableId</code> and an optional <code>partitionId</code>.</li>
<li><code>snapshotIds:</code> The latest snapshot ID specific to each bucket.</li>
<li><code>logOffsets:</code> The exact log position from which to resume reading after that snapshot, ensuring seamless data ingestion.</li>
</ul>
<p>With the <code>LakeSnapshot</code>, the live bucket offsets from the Fluss cluster, and (where applicable) the <code>KvSnapshots</code>, the <code>TieringSplitGenerator</code> performs its core function: it computes which log segments are present in Fluss but have not yet been committed to the lakehouse.</p>
<p>Finally, for each identified segment, it produces a distinct <strong>TieringSplit</strong>. Each <code>TieringSplit</code> precisely defines the specific bucket and the exact offset range that needs to be ingested. This meticulous process ensures incremental, highly efficient synchronization, seamlessly bridging your real-time operational data with your historical, cost-optimized storage.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="tieringsplit">TieringSplit<a href="#tieringsplit" class="hash-link" aria-label="Direct link to TieringSplit" title="Direct link to TieringSplit">​</a></h4>
<p>The <strong>TieringSplit</strong> abstraction defines exactly which slice of a table bucket needs to be synchronized. It captures three common fields:</p>
<ul>
<li><strong>tablePath</strong>: the full path to the target table.</li>
<li><strong>tableBucket</strong>: the specific bucket (shard) within that table.</li>
<li><strong>partitionName</strong> (optional): the partition key, if the table is partitioned.</li>
</ul>
<p>There are two concrete split types:</p>
<ol>
<li><strong>TieringLogSplit</strong> (for append-only “log” tables)<!-- -->
<ul>
<li><strong>startingOffset</strong>: the last committed log offset in the lake.</li>
<li><strong>stoppingOffset</strong>: the current end offset in the live Fluss bucket.</li>
<li>This split defines a contiguous range of new log records to ingest.</li>
</ul>
</li>
<li><strong>TieringSnapshotSplit</strong> (for primary-keyed tables)<!-- -->
<ul>
<li><strong>snapshotId</strong>: the identifier of the latest snapshot in Fluss.</li>
<li><strong>logOffsetOfSnapshot</strong>: the log offset at which that snapshot was taken.</li>
<li>This split lets the TieringSourceReader replay all CDC (change-data-capture) events since the snapshot, ensuring up-to-date state.</li>
</ul>
</li>
</ol>
<p>By breaking each table into these well-defined splits, the Tiering Service can incrementally, reliably, and in parallel sync exactly the data that’s missing from your data lake.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tieringsourcereader">TieringSourceReader<a href="#tieringsourcereader" class="hash-link" aria-label="Direct link to TieringSourceReader" title="Direct link to TieringSourceReader">​</a></h3>
<p><img decoding="async" loading="lazy" src="/assets/images/tiering-source-reader-2b300d7753ff2b30261ef3aec66f1f66.png" width="2012" height="1460" class="img_ev3q"></p>
<p>The <strong>TieringSourceReader</strong> pulls assigned splits from the enumerator, uses a <code>TieringSplitReader</code> to fetch the corresponding records from the Fluss server, and then writes them into the data lake. Its workflow breaks down as follows:</p>
<ul>
<li><strong>Split Selection:</strong> The reader picks an assigned <code>TieringSplit</code> from its queue.</li>
<li><strong>Reader Dispatch:</strong> Depending on the split type, it instantiates either:<!-- -->
<ul>
<li><strong>LogScanner</strong> for <code>TieringLogSplit</code> (append-only tables)</li>
<li><strong>BoundedSplitReader</strong> for <code>TieringSnapshotSplit</code> (primary-keyed tables)</li>
</ul>
</li>
<li><strong>Data Fetch:</strong> The chosen reader fetches the records defined by the split’s offset or snapshot boundaries from the Fluss server.</li>
<li><strong>Lake Writing&quot;</strong> Retrieved records are handed off to the lake writer, which persists them into the data lake.</li>
</ul>
<p>By cleanly separating split assignment, reader selection, data fetching, and lake writing, the TieringSourceReader ensures scalable, parallel ingestion of streaming and snapshot data into your lakehouse.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="lakewriter--laketieringfactory">LakeWriter &amp; LakeTieringFactory<a href="#lakewriter--laketieringfactory" class="hash-link" aria-label="Direct link to LakeWriter &amp; LakeTieringFactory" title="Direct link to LakeWriter &amp; LakeTieringFactory">​</a></h4>
<p>The LakeWriter is responsible for persisting Fluss records into your data lake, and it’s instantiated via a pluggable LakeTieringFactory. This interface defines how Fluss interacts with various lake formats (e.g., Paimon, Iceberg):</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">public</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(86, 156, 214)">interface</span><span class="token plain"> </span><span class="token class-name" style="color:rgb(78, 201, 176)">LakeTieringFactory</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">	</span><span class="token class-name" style="color:rgb(78, 201, 176)">LakeWriter</span><span class="token generics punctuation" style="color:rgb(212, 212, 212)">&lt;</span><span class="token generics class-name" style="color:rgb(78, 201, 176)">WriteResult</span><span class="token generics punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">createLakeWriter</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token class-name" style="color:rgb(78, 201, 176)">WriterInitContext</span><span class="token plain"> writerInitContext</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">	</span><span class="token class-name" style="color:rgb(78, 201, 176)">SimpleVersionedSerializer</span><span class="token generics punctuation" style="color:rgb(212, 212, 212)">&lt;</span><span class="token generics class-name" style="color:rgb(78, 201, 176)">WriteResult</span><span class="token generics punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">getWriteResultSerializer</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">	</span><span class="token class-name" style="color:rgb(78, 201, 176)">LakeCommitter</span><span class="token generics punctuation" style="color:rgb(212, 212, 212)">&lt;</span><span class="token generics class-name" style="color:rgb(78, 201, 176)">WriteResult</span><span class="token generics punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token generics"> </span><span class="token generics class-name" style="color:rgb(78, 201, 176)">CommittableT</span><span class="token generics punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">createLakeCommitter</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            </span><span class="token class-name" style="color:rgb(78, 201, 176)">CommitterInitContext</span><span class="token plain"> committerInitContext</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">	</span><span class="token class-name" style="color:rgb(78, 201, 176)">SimpleVersionedSerializer</span><span class="token generics punctuation" style="color:rgb(212, 212, 212)">&lt;</span><span class="token generics class-name" style="color:rgb(78, 201, 176)">CommittableT</span><span class="token generics punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">getCommittableSerializer</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><br></span></code></pre></div></div>
<ul>
<li><strong>createLakeWriter(WriterInitContext)</strong>: builds a <code>LakeWriter</code> to convert Fluss rows into the target table format.</li>
<li><strong>getWriteResultSerializer()</strong>: supplies a serializer for the writer’s output.</li>
<li><strong>createLakeCommitter(CommitterInitContext)</strong>: constructs a <code>LakeCommitter</code> to finalize and atomically commit data files.</li>
<li><strong>getCommittableSerializer()</strong>: provides a serializer for committable tokens.```</li>
</ul>
<p>By default, Fluss includes a Paimon-backed tiering factory; Iceberg support is coming soon. Once the <code>TieringSourceReader</code> writes a batch of records through the <code>LakeWriter</code>, it emits the resulting write metadata downstream to the <strong>TieringCommitOperator</strong>, which then commits those changes both in the lakehouse and back to the Fluss cluster.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="stateless">Stateless<a href="#stateless" class="hash-link" aria-label="Direct link to Stateless" title="Direct link to Stateless">​</a></h4>
<p>The <code>TieringSourceReader</code> is designed to be completely stateless—it does not checkpoint or store any <code>TieringSplit</code> information itself. Instead, every checkpoint simply returns an empty list, leaving all split-tracking to the <code>TieringSourceEnumerator</code>:</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token annotation punctuation" style="color:rgb(212, 212, 212)">@Override</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">public</span><span class="token plain"> </span><span class="token class-name" style="color:rgb(78, 201, 176)">List</span><span class="token generics punctuation" style="color:rgb(212, 212, 212)">&lt;</span><span class="token generics class-name" style="color:rgb(78, 201, 176)">TieringSplit</span><span class="token generics punctuation" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">snapshotState</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token keyword" style="color:rgb(86, 156, 214)">long</span><span class="token plain"> checkpointId</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token comment" style="color:rgb(106, 153, 85)">// Stateless: no splits are held in reader state</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token keyword" style="color:rgb(86, 156, 214)">return</span><span class="token plain"> </span><span class="token class-name" style="color:rgb(78, 201, 176)">Collections</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token function" style="color:rgb(220, 220, 170)">emptyList</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><br></span></code></pre></div></div>
<p>By delegating split assignment entirely to the Enumerator, the reader remains lightweight and easily scalable, always fetching its next work unit afresh from the coordinator.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tieringcommitter">TieringCommitter<a href="#tieringcommitter" class="hash-link" aria-label="Direct link to TieringCommitter" title="Direct link to TieringCommitter">​</a></h2>
<p><img decoding="async" loading="lazy" src="/assets/images/tiering-committer-c331413f2e4953539e9df51e711ca4f4.png" width="1930" height="1592" class="img_ev3q"></p>
<p>The <strong>TieringCommitter</strong> operator wraps up each sync cycle by taking the <code>WriteResult</code> outputs from the TieringSourceReader and committing them in two phases:
first to the data lake, then back to Fluss, before emitting status events to the Flink coordinator. It leverages two  components:</p>
<ul>
<li><strong>LakeCommitter</strong>: Provided by the pluggable <code>LakeTieringFactory</code>, this component atomically commits the written files into the lakehouse and returns the new snapshot ID.</li>
<li><strong>FlussTableLakeSnapshotCommitter</strong>: Using that snapshot ID, it updates the Fluss cluster’s tiering table status so that the Fluss server and lakehouse remain in sync.</li>
</ul>
<p>The end-to-end flow is:</p>
<ol>
<li><strong>Collect Write Results</strong> from the TieringSourceReader for the current checkpoint.</li>
<li><strong>Lake Commit</strong> via the <code>LakeCommitter</code>, which finalizes files and advances the lake snapshot.</li>
<li><strong>Fluss Update</strong> using the <code>FlussTableLakeSnapshotCommitter</code>, acknowledging success or failure back to the Fluss CoordinatorService.</li>
<li><strong>Event Emission</strong> of either <code>FinishedTieringEvent</code> (on success or completion) or <code>FailedTieringEvent</code> (on errors) to the Flink <code>OperatorCoordinator</code>.</li>
</ol>
<p>This TieringCommitter operator ensures exactly-once consistent synchronization between your real-time Fluss cluster and your analytical lakehouse.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>In this deep dive, we thoroughly explored every facet of Fluss&#x27;s <strong>Tiering Service</strong>.
We began by dissecting the <strong>TieringSource</strong>, understanding the critical roles of its Enumerator, RpcClient, and SplitGenerator. From there, we examined the various split types and the efficiency of the stateless <strong>TieringSourceReader</strong>.</p>
<p>Our journey then led us to the flexible, pluggable integration of the <strong>LakeWriter</strong> and <strong>LakeCommitter</strong>. Finally, we saw how the <strong>TieringCommitter</strong>, with its LakeCommitter and FlussTableLakeSnapshotCommitter, orchestrates <strong>atomic</strong>, <strong>exactly-once commits</strong> across both your data lake and Fluss cluster.</p>
<p>Together, these components form a robust pipeline. This pipeline reliably synchronizes real-time streams with historical snapshots, ensuring <strong>seamless</strong>, <strong>scalable consistency</strong> between your live workloads and analytical storage.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/fluss-java-client/"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Apache Fluss Java Client: A Deep Dive</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/releases/0.7/"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Announcing Fluss 0.7</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#background" class="table-of-contents__link toc-highlight">Background</a></li><li><a href="#flink-tiering-service" class="table-of-contents__link toc-highlight">Flink Tiering Service</a></li><li><a href="#tieringsource" class="table-of-contents__link toc-highlight">TieringSource</a><ul><li><a href="#tieringsourceenumerator" class="table-of-contents__link toc-highlight">TieringSourceEnumerator</a><ul><li><a href="#rpcclient" class="table-of-contents__link toc-highlight">RpcClient</a></li><li><a href="#tieringsplitgenerator" class="table-of-contents__link toc-highlight">TieringSplitGenerator</a></li><li><a href="#tieringsplit" class="table-of-contents__link toc-highlight">TieringSplit</a></li></ul></li><li><a href="#tieringsourcereader" class="table-of-contents__link toc-highlight">TieringSourceReader</a><ul><li><a href="#lakewriter--laketieringfactory" class="table-of-contents__link toc-highlight">LakeWriter &amp; LakeTieringFactory</a></li><li><a href="#stateless" class="table-of-contents__link toc-highlight">Stateless</a></li></ul></li></ul></li><li><a href="#tieringcommitter" class="table-of-contents__link toc-highlight">TieringCommitter</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 The Apache Software Foundation.
      Apache®, Apache Flink®, Flink®, Apache Kafka®, Kafka®, Spark® and associated open source project names and logos are trademarks of the Apache Software Foundation.</div></div></div></footer></div>
</body>
</html>