<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Towards A Unified Streaming &amp; Lakehouse Architecture | Fluss</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://fluss.apache.org/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://fluss.apache.org/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://fluss.apache.org/blog/unified-streaming-lakehouse/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Towards A Unified Streaming &amp; Lakehouse Architecture | Fluss"><meta data-rh="true" name="description" content="&lt;!--"><meta data-rh="true" property="og:description" content="&lt;!--"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-01-28T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/luoyuxia"><link data-rh="true" rel="icon" href="/img/logo/fluss_favicon.svg"><link data-rh="true" rel="canonical" href="https://fluss.apache.org/blog/unified-streaming-lakehouse/"><link data-rh="true" rel="alternate" href="https://fluss.apache.org/blog/unified-streaming-lakehouse/" hreflang="en"><link data-rh="true" rel="alternate" href="https://fluss.apache.org/blog/unified-streaming-lakehouse/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://D8RXQUTC99-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://fluss.apache.org/blog/unified-streaming-lakehouse","mainEntityOfPage":"https://fluss.apache.org/blog/unified-streaming-lakehouse","url":"https://fluss.apache.org/blog/unified-streaming-lakehouse","headline":"Towards A Unified Streaming & Lakehouse Architecture","name":"Towards A Unified Streaming & Lakehouse Architecture","description":"<!--","datePublished":"2025-01-28T00:00:00.000Z","author":{"@type":"Person","name":"Luo Yuxia","description":"Fluss Committer","url":"https://github.com/luoyuxia","image":"https://github.com/luoyuxia.png"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://fluss.apache.org/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Fluss RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Fluss Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="Fluss" href="/opensearch.xml">

<link rel="icon" href="/img/logo.svg">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="#0071e3"><link rel="stylesheet" href="/assets/css/styles.3ca55d09.css">
<script src="/assets/js/runtime~main.264c6f6f.js" defer="defer"></script>
<script src="/assets/js/main.a06cb6b9.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo/svg/colored_logo.svg" alt="Fluss" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo/svg/colored_logo.svg" alt="Fluss" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href="/docs/intro/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog/">Blog</a><a class="navbar__item navbar__link" href="/community/welcome/">Community</a><a class="navbar__item navbar__link" href="/roadmap/">Roadmap</a><a class="navbar__item navbar__link" href="/downloads/">Downloads</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/apache/fluss" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All our posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/releases/0.7/">Announcing Fluss 0.7</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/partial-updates/">Understanding Partial Updates</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/unveil-fluss-logo/">The Story of Fluss Logo</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/releases/0.6/">Announcing Fluss 0.6</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/unified-streaming-lakehouse/">Toward Streaming Lakehouse</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2024</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/fluss-intro/">Introducing Fluss</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/why-fluss/">Why Fluss? Top 4 Challenges of Kafka</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/fluss-open-source/">Fluss is Now Open Source</a></li></ul></div></nav></aside><main class="col col--7"><article class=""><header><h1 class="title_f1Hy">Towards A Unified Streaming &amp; Lakehouse Architecture</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-01-28T00:00:00.000Z">January 28, 2025</time></div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/luoyuxia" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/luoyuxia.png" alt="Luo Yuxia"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/luoyuxia" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Luo Yuxia</span></a></div><small class="authorTitle_nd0D" title="Fluss Committer">Fluss Committer</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p>The unification of Lakehouse and streaming storage represents a major trend in the future development of modern data lakes and streaming storage systems. Designed specifically for real-time analytics, Fluss has embraced a unified Streaming and Lakehouse architecture from its inception, enabling seamless integration into existing Lakehouse architectures.</p>
<p>Fluss is designed to address the demands of real-time analytics with the following key capabilities:</p>
<ul>
<li><strong>Real-Time Stream Reading and Writing:</strong> Supports millisecond-level end-to-end latency.</li>
<li><strong>Columnar Stream:</strong> Optimizes storage and query efficiency.</li>
<li><strong>Streaming Updates:</strong> Enables low-latency updates to data streams.</li>
<li><strong>Changelog Generation:</strong> Supports changelog generation and consumption.</li>
<li><strong>Real-Time Lookup Queries:</strong> Facilitates instant lookup queries on primary keys.</li>
<li><strong>Streaming &amp; Lakehouse Unification:</strong> Seamlessly integrates streaming and lakehouse storage for unified data processing.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="fluss-unified-streaming--lakehouse-architecture">Fluss Unified Streaming &amp; Lakehouse Architecture<a href="#fluss-unified-streaming--lakehouse-architecture" class="hash-link" aria-label="Direct link to Fluss Unified Streaming &amp; Lakehouse Architecture" title="Direct link to Fluss Unified Streaming &amp; Lakehouse Architecture">​</a></h3>
<p><img decoding="async" loading="lazy" alt="Unification Solutions" src="/assets/images/img1-163f1412a1ed7b661686302df5bf9edb.png" width="1866" height="635" class="img_ev3q">
The Fluss architecture is designed to provide millisecond-level end-to-end latency, ensuring high-performance real-time data writing and reading. A core component of this architecture is the <strong>Tiering Service</strong>, which continuously offloads data in Fluss into a standard lakehouse format, such as <code>Apache Paimon</code> or <code>Apache Iceberg</code>. This tiering ensures that external query engines can directly analyze data in the Lakehouse format, enabling efficient batch and real-time analytics.
In this architecture:</p>
<ul>
<li><strong>Latest Data in Fluss:</strong> Fluss stores the most recent, high-fidelity data for real-time analytics.</li>
<li><strong>Historical Data in Paimon:</strong> Older data is compacted and stored in Apache Paimon for large-scale historical analysis.</li>
</ul>
<p>By leveraging Apache Flink, the integration of Fluss and Paimon supports Union Reads, which combine real-time data in Fluss with historical data in Paimon. This enables analytical queries with second-level freshness, allowing businesses to benefit from up-to-date insights while maintaining access to extensive historical datasets.</p>
<p>The Streaming/Lakehouse unification design of Fluss provides:</p>
<ul>
<li><strong>Unified Architecture:</strong> Simplifies the Lakehouse ecosystem by combining the strengths of streaming and Lakehouse storage.</li>
<li><strong>Enhanced Real-Time Capabilities:</strong> Millisecond-level latency ensures data is always fresh for critical use cases.</li>
<li><strong>Seamless Compatibility:</strong> Native support for standard lakehouse formats ensures interoperability with existing analytics engines.</li>
<li><strong>Optimized Data Management:</strong> Combines real-time and historical data seamlessly for comprehensive analytics workflows.</li>
</ul>
<p>Fluss is <strong>a next-generation approach to streaming storage, purpose-built to complement Lakehouse architectures</strong> and drive the adoption of a streaming and Lakehouse unification across industries.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="unified-metadata">Unified metadata<a href="#unified-metadata" class="hash-link" aria-label="Direct link to Unified metadata" title="Direct link to Unified metadata">​</a></h3>
<p><img decoding="async" loading="lazy" alt="Unification Solutions" src="/assets/images/img2-86b0eb7b0f26884f8ead16dc4a8db648.png" width="1842" height="732" class="img_ev3q"></p>
<p>In traditional architectures, streaming storage systems like Kafka and Lakehouse storage solutions like Apache Paimon operated as distinct entities, each maintaining its own metadata. For computing engines such as Apache Flink, this separation presented two significant challenges:</p>
<ol>
<li><strong>Dual Catalogs:</strong> Users were required to create and manage two separate catalogs—one for streaming storage and another for lake storage.</li>
<li><strong>Manual Switching:</strong> Accessing data involved manually switching between catalogs to determine whether to query stream storage or lake storage, resulting in operational complexity and inefficiencies.</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="unified-access-in-fluss">Unified Access in Fluss<a href="#unified-access-in-fluss" class="hash-link" aria-label="Direct link to Unified Access in Fluss" title="Direct link to Unified Access in Fluss">​</a></h3>
<p>In the Fluss, although Fluss and Paimon still maintain independent metadata, they expose a unified catalog and a single table abstraction to the computing engine, such as Apache Flink. This unified approach offers several key advantages:</p>
<ul>
<li><strong>Simplified Data Access:</strong> Users can seamlessly access both Lakehouse storage (Paimon) and streaming storage (Fluss) through a single catalog, eliminating the need to manage or switch between separate catalogs.</li>
<li><strong>Integrated Querying:</strong> The unified table abstraction allows direct access to real-time data in Fluss and historical data in Paimon. For scenarios requiring both, users can leverage <code>Union Reads</code>, combining data from Fluss and Paimon to enable comprehensive analytics with second-level data freshness.</li>
<li><strong>Operational Efficiency:</strong> By presenting a cohesive interface, the architecture reduces operational complexity, making it easier for users to work with real-time and historical data within a single workflow.</li>
</ul>
<p>This unified approach streamlines the interaction between computing engines and storage layers, enhancing both usability and productivity while supporting the high-performance demands of modern analytics workflows.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="alignment-of-data-distribution">Alignment of Data Distribution<a href="#alignment-of-data-distribution" class="hash-link" aria-label="Direct link to Alignment of Data Distribution" title="Direct link to Alignment of Data Distribution">​</a></h3>
<p><img decoding="async" loading="lazy" alt="Unification Solutions" src="/assets/images/img3-d0ea956fb83807118c4d522bdd7b30f4.png" width="1777" height="856" class="img_ev3q"></p>
<p>In the Fluss, the data distribution between Fluss and Lakehouse storage (e.g., Apache Paimon) is strictly aligned. Fluss supports partitioned tables and buckets, and its bucketing algorithm is fully consistent with Paimon’s. This ensures that a given piece of data is always allocated to the same bucket in both systems, creating a one-to-one correspondence between Fluss buckets and Paimon buckets.
This strong consistency in data distribution provides two significant benefits:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-elimination-of-shuffle-overhead-during-tiering">1. Elimination of Shuffle Overhead During Tiering<a href="#1-elimination-of-shuffle-overhead-during-tiering" class="hash-link" aria-label="Direct link to 1. Elimination of Shuffle Overhead During Tiering" title="Direct link to 1. Elimination of Shuffle Overhead During Tiering">​</a></h4>
<p>When tiering data from Fluss into Paimon format:</p>
<ul>
<li>A Fluss bucket (e.g., bucket1) can be tiered directly into the corresponding Paimon bucket (bucket1).</li>
<li>There is no need to read data from a Fluss bucket, calculate which Paimon bucket each piece of data belongs to, and then write it to the appropriate Paimon bucket.</li>
</ul>
<p>By bypassing this intermediate redistribution step, the architecture avoids costly shuffle overhead, significantly improving compaction efficiency.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-prevention-of-data-inconsistencies">2. Prevention of Data Inconsistencies<a href="#2-prevention-of-data-inconsistencies" class="hash-link" aria-label="Direct link to 2. Prevention of Data Inconsistencies" title="Direct link to 2. Prevention of Data Inconsistencies">​</a></h4>
<p>Data consistency is maintained through the use of an identical bucketing algorithm in both Fluss and Paimon. This algorithm calculates the bucket assignment for each piece of data as follows:</p>
<blockquote>
<p>bucket_id = hash(row) % bucket_num</p>
</blockquote>
<p>By employing the same hash function and algorithm, Fluss and Paimon ensure consistent bucket assignment. If differing algorithms were used, inconsistencies would arise. For example:</p>
<ul>
<li>For a primary key table, a data row a might be assigned to bucket1 in Fluss but to bucket2 in Paimon.</li>
<li>During tiering, if rows were mistakenly placed in bucket1 in Paimon (per Fluss’s assignment), users would fail to locate the data in Paimon due to the mismatch.</li>
</ul>
<p>By maintaining strong alignment in data distribution, the architecture eliminates this risk, ensuring data consistency across Fluss and Paimon while simplifying compaction workflows. This alignment underscores the robustness and efficiency of the Fluss unification design.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="streaming-reading-more-efficient-data-tracing">Streaming Reading: More Efficient Data Tracing<a href="#streaming-reading-more-efficient-data-tracing" class="hash-link" aria-label="Direct link to Streaming Reading: More Efficient Data Tracing" title="Direct link to Streaming Reading: More Efficient Data Tracing">​</a></h3>
<p>In the Fluss, historical data resides in Lakehouse storage, while real-time data is maintained in Fluss. During streaming reads, this architecture enables a seamless combination of historical and real-time data access:</p>
<ul>
<li><strong>Historical Data Access:</strong> Fluss retrieves historical data directly from the Lakehouse storage, leveraging its inherent advantages, such as:<!-- -->
<ul>
<li><strong>Efficient Filter Pushdown:</strong> Enables query engines to apply filtering conditions at the storage layer, reducing the amount of data read and improving performance.</li>
<li><strong>Column Pruning:</strong> Allows retrieval of only the necessary columns, optimizing data transfer and query efficiency.</li>
<li><strong>High Compression Ratios:</strong> Minimizes storage overhead while maintaining fast retrieval speeds.</li>
</ul>
</li>
<li><strong>Real-Time Data Access:</strong> Fluss concurrently reads the latest real-time data from its own storage, ensuring up-to-the-millisecond freshness.</li>
</ul>
<p>By combining the strengths of Lakehouse storage for efficient historical data retrieval and Fluss for real-time streaming data, this architecture delivers a highly performant and scalable solution for streaming read scenarios. This integration ensures that users benefit from low-latency data freshness and optimized query performance across both historical and real-time datasets.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="batch-reading-data-freshness-in-seconds">Batch Reading: Data Freshness in Seconds<a href="#batch-reading-data-freshness-in-seconds" class="hash-link" aria-label="Direct link to Batch Reading: Data Freshness in Seconds" title="Direct link to Batch Reading: Data Freshness in Seconds">​</a></h3>
<p><img decoding="async" loading="lazy" alt="Unification Solutions" src="/assets/images/img4-06aab50ae6bb5a5df5cc0e2658815c1f.png" width="1770" height="747" class="img_ev3q"></p>
<p>Historical data is stored in the Lakehouse, and real-time data is stored in Fluss. In batch reading scenarios, computing engines (such as Flink) can perform union reading of data in Fluss and lake storage to achieve analysis of data freshness in seconds.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache-flink-and-fluss">Apache Flink and Fluss<a href="#apache-flink-and-fluss" class="hash-link" aria-label="Direct link to Apache Flink and Fluss" title="Direct link to Apache Flink and Fluss">​</a></h3>
<p><img decoding="async" loading="lazy" alt="Unification Solutions" src="/assets/images/img5-36f56d95c22f50252c6a5caedbfed1d4.png" width="1761" height="730" class="img_ev3q">
Fluss exposes a unified API to Flink users, allowing them to choose whether to use union reads or read-only reads on the Lakehouse, using the following SQL:</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">SELECT</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(86, 156, 214)">FROM</span><span class="token plain"> orders</span><br></span></code></pre></div></div>
<p>This reads the complete data of the orders table and Flink will union read the data in Fluss and the Lakehouse.
If the user only needs to read data on the data lake, you can add the <code>$lake</code> suffix after the table to be read. The SQL is as follows</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)">-- analytical queries</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">SELECT</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">COUNT</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token operator" style="color:rgb(212, 212, 212)">*</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">MAX</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">t</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">SUM</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">amount</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">FROM</span><span class="token plain"> orders$lake</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)">-- query system tables</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">SELECT</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(86, 156, 214)">FROM</span><span class="token plain"> orders$lake$snapshots</span><br></span></code></pre></div></div>
<p>For scenarios where data on a data lake is read-only, Fluss inherits all the optimizations and capabilities of the lake format as a Flink source, such as runtime filters, system table queries, and time travel.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benefits-of-the-unified-architecture">Benefits Of The Unified Architecture<a href="#benefits-of-the-unified-architecture" class="hash-link" aria-label="Direct link to Benefits Of The Unified Architecture" title="Direct link to Benefits Of The Unified Architecture">​</a></h2>
<p>Next, using Apache Paimon as an example, we will illustrate the advantages of using Fluss to build a unified architecture. We will highlight how Fluss enhances the capabilities of Paimon, creating a unified solution that combines the strengths of both systems for efficient real-time and historical data processing.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="second-level-timeliness">Second-level Timeliness<a href="#second-level-timeliness" class="hash-link" aria-label="Direct link to Second-level Timeliness" title="Direct link to Second-level Timeliness">​</a></h3>
<p>In Apache Paimon, data visibility is traditionally determined by the Flink checkpoint interval, which typically operates at one minute-level granularity. However, by integrating Fluss with Paimon to build unfiied architecture, this dependency is eliminated.</p>
<p>With this unification, data becomes visible immediately upon entering Fluss, significantly improving data timeliness to second-level latency. This enhancement ensures that real-time insights can be derived more quickly, meeting the demands of time-sensitive applications while maintaining seamless access to both historical and real-time data.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="consistent-data-freshness-across-all-layers">Consistent Data Freshness Across All Layers<a href="#consistent-data-freshness-across-all-layers" class="hash-link" aria-label="Direct link to Consistent Data Freshness Across All Layers" title="Direct link to Consistent Data Freshness Across All Layers">​</a></h3>
<p><img decoding="async" loading="lazy" alt="Unification Solutions" src="/assets/images/img6-5fdec641b3032d1c0f236cf990d914da.png" width="1570" height="782" class="img_ev3q">
In the process of building a data warehouse, it is common to organize and manage data by layering, such as Bronze, Silver and Gold following the medallion architecture. As data flows through these layers, maintaining data freshness becomes a critical consideration.</p>
<p>When Paimon is used as the sole storage solution for each layer, data visibility depends on the Flink checkpoint interval. This introduces cumulative delays:</p>
<ul>
<li>The changelog for a given layer becomes visible only after the completion of a Flink checkpoint.</li>
<li>As this changelog propagates to subsequent layers, the data freshness delay increases with each checkpoint interval.</li>
</ul>
<p>For example, with a Flink checkpoint interval of 1 minute:</p>
<ul>
<li>The Bronze layer experiences 1-minute delay.</li>
<li>The Silver layer adds another 1-minute delay, totaling 2 minutes.</li>
<li>The Gold layer adds yet another 1-minute delay, resulting in a cumulative 3-minute delay.</li>
</ul>
<p>With Fluss and Paimon though we get:</p>
<ul>
<li><strong>Immediate Data Visibility:</strong> Data in Fluss becomes visible immediately upon ingestion, without waiting for a Flink checkpoint to complete. The changelog is instantly transferred to the next layer.</li>
<li><strong>Consistent Data Freshness:</strong> The data freshness across all layers is consistent and measured in seconds, eliminating cumulative delays.</li>
</ul>
<p>Additionally, if the Fluss Tiering Service is configured with a tiering cycle of 1 minute, the data delay for Paimon storage at each layer is limited to 1 minute, regardless of the number of layers. This ensures:</p>
<ul>
<li><strong>Real-Time Data Processing:</strong> Layers can propagate and process data with minimal delay.</li>
<li><strong>Optimized Streaming &amp; Lakehouse Unification:</strong> The architecture balances the strengths of real-time and batch-oriented storage.</li>
</ul>
<p>This integration significantly improves the performance and usability of layered data warehouses, enabling faster insights and better responsiveness to real-time demands.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="more-efficient-and-higher-throughput-changelog-generation">More efficient and higher throughput changelog generation<a href="#more-efficient-and-higher-throughput-changelog-generation" class="hash-link" aria-label="Direct link to More efficient and higher throughput changelog generation" title="Direct link to More efficient and higher throughput changelog generation">​</a></h3>
<p>In Apache Paimon, there are currently two commonly used methods for generating changelogs (excluding the Input Producer, which requires more stringent data source requirements and is not considered here):</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="lookup-changelog-producer">Lookup Changelog Producer<a href="#lookup-changelog-producer" class="hash-link" aria-label="Direct link to Lookup Changelog Producer" title="Direct link to Lookup Changelog Producer">​</a></h4>
<ul>
<li><strong>Advantages:</strong> Offers high timeliness for generating changelogs.</li>
<li><strong>Challenges:</strong> Consumes significant computational resources, leading to higher operational costs.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="full-compaction-producer">Full Compaction Producer:<a href="#full-compaction-producer" class="hash-link" aria-label="Direct link to Full Compaction Producer:" title="Direct link to Full Compaction Producer:">​</a></h4>
<ul>
<li><strong>Advantages:</strong> Does not require additional resource consumption, as changelogs are generated during the Full Compaction process.</li>
<li><strong>Challenges:</strong> Suffers from poor timeliness, as changelog generation is delayed until a Full Compaction is triggered, which typically occurs after several checkpoints.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="fluss-and-paimon-optimizing-changelog-generation">Fluss and Paimon: Optimizing Changelog Generation<a href="#fluss-and-paimon-optimizing-changelog-generation" class="hash-link" aria-label="Direct link to Fluss and Paimon: Optimizing Changelog Generation" title="Direct link to Fluss and Paimon: Optimizing Changelog Generation">​</a></h4>
<p>The Fluss and Paimon architecture strikes a balance between timeliness and performance in changelog generation:</p>
<ul>
<li><strong>Changelog Timeliness:</strong> Fluss generates changelogs in seconds, ensuring near real-time visibility of data changes.</li>
<li><strong>Efficient Conversion:</strong> The Fluss Tiering Service efficiently writes Fluss changelogs directly into the Paimon changelog format. This conversion process is highly optimized, avoiding resource-intensive operations such as lookups. Instead, it relies on direct read-and-write operations, significantly reducing overhead.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="key-benefits-of-fluss-and-paimon-changelog-generation">Key Benefits of Fluss and Paimon Changelog Generation<a href="#key-benefits-of-fluss-and-paimon-changelog-generation" class="hash-link" aria-label="Direct link to Key Benefits of Fluss and Paimon Changelog Generation" title="Direct link to Key Benefits of Fluss and Paimon Changelog Generation">​</a></h4>
<ol>
<li><strong>Improved Timeliness:</strong> Near real-time changelog generation ensures data freshness and faster insights.</li>
<li><strong>Resource Efficiency:</strong> By eliminating the need for computationally expensive operations, the architecture reduces resource consumption while maintaining high performance.</li>
<li><strong>Seamless Integration:</strong> The direct compatibility between Fluss changelogs and Paimon changelog formats simplifies the process, enhancing system efficiency and reducing operational complexity.</li>
</ol>
<p>This architecture provides an elegant solution for use cases that demand both low-latency data updates and optimized resource utilization, making it a robust choice for modern data processing needs.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="enabling-multi-writer-support-for-paimon-partial-updates">Enabling Multi-Writer Support for Paimon Partial Updates<a href="#enabling-multi-writer-support-for-paimon-partial-updates" class="hash-link" aria-label="Direct link to Enabling Multi-Writer Support for Paimon Partial Updates" title="Direct link to Enabling Multi-Writer Support for Paimon Partial Updates">​</a></h3>
<p>Partial updates are a critical feature in Apache Paimon, particularly for managing large, wide tables. However, in the current Paimon architecture, performing partial updates on wide tables presents significant challenges:</p>
<ul>
<li><strong>Single Writer Limitation:</strong> To ensure consistency, all partial updates to a table must be consolidated into a single SQL job. This requires using a UNION statement to combine all partial update operations into a single pipeline, ensuring only one writer is responsible for updating the table.</li>
<li><strong>Operational Complexity:</strong> Consolidating all updates into one job makes it difficult to manage and tune individual update operations, leading to challenges in scalability and flexibility.</li>
</ul>
<p>With Fluss and Paimon integration these limitations are eliminated</p>
<p><img decoding="async" loading="lazy" alt="Unification Solutions" src="/assets/images/img7-8b8e86a6e036ca0f37b6d53f8fc5ae77.png" width="1833" height="783" class="img_ev3q"></p>
<ul>
<li><strong>Intermediate Synchronization via Fluss:</strong> All updates pass through Fluss, which serves as an intermediary layer to synchronize changes with Paimon.</li>
<li><strong>Support for Concurrent Updates:</strong> Fluss enables concurrent updates from multiple SQL jobs, removing the need to consolidate updates into a single job.</li>
<li><strong>Fine-Grained Job Management:</strong> With the ability to execute multiple independent SQL jobs for updating any number of columns in a wide table, users can perform job-level tuning and management, improving operational efficiency and flexibility.</li>
</ul>
<p>This enables organizations to unlock several key advantages:</p>
<ul>
<li><strong>High Real-Time Performance:</strong> Lakehouse storage achieves second-level data freshness, meeting the demands of real-time data applications.</li>
<li><strong>Unified Streaming and Lakehouse Processing:</strong> Data is written once into the architecture and can seamlessly support both batch and streaming use cases, reducing duplication of effort.</li>
<li><strong>Lower Operational Costs:</strong> Simplified maintenance and reduced complexity of partial updates, lower storage costs by minimizing data duplication and reduced computational costs by eliminating redundant processing pipelines.</li>
</ul>
<p>The Fluss and Paimon architecture offers a robust solution for managing partial updates in wide tables while delivering significant improvements in performance, scalability, and operational efficiency.</p>
<p>All the above highlight the power of a unified streaming and Lakehouse architecture in modern data systems, ensuring real-time capabilities with streamlined workflows.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-plans">Future plans<a href="#future-plans" class="hash-link" aria-label="Direct link to Future plans" title="Direct link to Future plans">​</a></h2>
<p>The Fluss community is actively working to enhance the streaming and Lakehouse unification capabilities, focusing on the following key areas.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="expanding-union-read-ecosystem">Expanding Union Read Ecosystem<a href="#expanding-union-read-ecosystem" class="hash-link" aria-label="Direct link to Expanding Union Read Ecosystem" title="Direct link to Expanding Union Read Ecosystem">​</a></h3>
<p>Currently, Union Read functionality is integrated with Apache Flink, enabling seamless querying of real-time and historical data. Moving forward, the community plans to extend this capability to support additional query engines, such as Apache Spark and StarRocks, further broadening its ecosystem compatibility and adoption.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="diversifying-lake-storage-formats">Diversifying Lake Storage Formats<a href="#diversifying-lake-storage-formats" class="hash-link" aria-label="Direct link to Diversifying Lake Storage Formats" title="Direct link to Diversifying Lake Storage Formats">​</a></h3>
<p>At present, Fluss supports Apache Paimon as its primary lake storage. To meet diverse user requirements, the community aims to add support for more lake formats, including <strong>Apache Iceberg</strong> and <strong>Apache Hudi</strong>, thereby providing flexibility and interoperability with a wider range of Lakehouse ecosystems.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="optimizing-arrow-to-parquet-conversion">Optimizing Arrow-to-Parquet Conversion<a href="#optimizing-arrow-to-parquet-conversion" class="hash-link" aria-label="Direct link to Optimizing Arrow-to-Parquet Conversion" title="Direct link to Optimizing Arrow-to-Parquet Conversion">​</a></h3>
<p>Fluss leverages Apache Arrow as its storage format, while many Lakehouse formats, such as Paimon, Iceberg, and Hudi, utilize parquet for storage. The Apache Arrow community has developed a mature and efficient solution for converting Arrow data to Parquet. In the future, Fluss will integrate these advancements to enable high-performance Arrow-to-Parquet conversions, significantly reducing the computational overhead of the tiering service and enhancing overall efficiency.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/releases/0.6/"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Announcing Fluss 0.6</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/fluss-intro/"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Introducing Fluss: Streaming Storage for Real-Time Analytics</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#fluss-unified-streaming--lakehouse-architecture" class="table-of-contents__link toc-highlight">Fluss Unified Streaming &amp; Lakehouse Architecture</a></li><li><a href="#unified-metadata" class="table-of-contents__link toc-highlight">Unified metadata</a></li><li><a href="#unified-access-in-fluss" class="table-of-contents__link toc-highlight">Unified Access in Fluss</a></li><li><a href="#alignment-of-data-distribution" class="table-of-contents__link toc-highlight">Alignment of Data Distribution</a></li><li><a href="#streaming-reading-more-efficient-data-tracing" class="table-of-contents__link toc-highlight">Streaming Reading: More Efficient Data Tracing</a></li><li><a href="#batch-reading-data-freshness-in-seconds" class="table-of-contents__link toc-highlight">Batch Reading: Data Freshness in Seconds</a></li><li><a href="#apache-flink-and-fluss" class="table-of-contents__link toc-highlight">Apache Flink and Fluss</a></li><li><a href="#benefits-of-the-unified-architecture" class="table-of-contents__link toc-highlight">Benefits Of The Unified Architecture</a><ul><li><a href="#second-level-timeliness" class="table-of-contents__link toc-highlight">Second-level Timeliness</a></li><li><a href="#consistent-data-freshness-across-all-layers" class="table-of-contents__link toc-highlight">Consistent Data Freshness Across All Layers</a></li><li><a href="#more-efficient-and-higher-throughput-changelog-generation" class="table-of-contents__link toc-highlight">More efficient and higher throughput changelog generation</a></li><li><a href="#enabling-multi-writer-support-for-paimon-partial-updates" class="table-of-contents__link toc-highlight">Enabling Multi-Writer Support for Paimon Partial Updates</a></li></ul></li><li><a href="#future-plans" class="table-of-contents__link toc-highlight">Future plans</a><ul><li><a href="#expanding-union-read-ecosystem" class="table-of-contents__link toc-highlight">Expanding Union Read Ecosystem</a></li><li><a href="#diversifying-lake-storage-formats" class="table-of-contents__link toc-highlight">Diversifying Lake Storage Formats</a></li><li><a href="#optimizing-arrow-to-parquet-conversion" class="table-of-contents__link toc-highlight">Optimizing Arrow-to-Parquet Conversion</a></li></ul></li></ul></div></div></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 The Apache Software Foundation.
      Apache®, Apache Flink®, Flink®, Apache Kafka®, Kafka®, Spark® and associated open source project names and logos are trademarks of the Apache Software Foundation.</div></div></div></footer></div>
</body>
</html>